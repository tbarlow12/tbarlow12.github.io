{
  "My Software Dev Bucket List": {
    "name": "BucketList.md",
    "content": "---\r\ntitle: My Software Dev Bucket List\r\ndate: 2018-8-31\r\npreview: This is my software dev bucket list\r\n---\r\n\r\nThis is an ever-growing, ever-changing list of things I would like to accomplish as a software engineer, both in my professional and personal life.\r\n\r\n- [ ] Find an interesting open-source project and submit a PR within 24 hours \r\n- [ ] File a patent for software you wrote (at work or otherwise)\r\n- [x] Write a REST API\r\n- [x] Write a serverless function\r\n- [x] Containerize an application\r\n- [x] Make your own website\r\n- [ ] Work pager duty\r\n- [x] Participate in a hackathon\r\n- [x] Travel to attend a major software conference\r\n- [ ] Travel to speak or present at a major software conference\r\n- [x] Find a senior developer mentor\r\n- [ ] Mentor a junior developer\r\n- [ ] Submit code to these online package managers\r\n    - [x] PyPI\r\n    - [x] NuGet\r\n    - [ ] NPM\r\n- [ ] Have a stranger submit a meaningful PR to an open-source project you created\r\n- [ ] Pull an all-nighter coding on a personal project\r\n- [x] Write a piece of software just for you that you actually use\r\n- [ ] Reading list: \r\n    - [ ] [Clean Code](https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882)\r\n    - [x] [The Night Watch](https://www.usenix.org/system/files/1311_05-08_mickens.pdf)\r\n    - [x] [Cracking the Coding Interview](https://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/0984782850/ref=dp_ob_title_bk)\r\n    - [ ] [Design Patterns: Elements of Reusable Object-Oriented Software](https://www.amazon.com/Design-Patterns-Elements-Reusable-Object-Oriented/dp/0201633612)\r\n    - [ ] [Code: The Hidden Language of Computer Hardware and Software](https://www.amazon.com/Code-Language-Computer-Hardware-Software/dp/0735611319)\r\n    - [ ] [Refactoring: Improving the Design of Existing Code](https://www.amazon.com/Refactoring-Improving-Design-Existing-Code/dp/0201485672)\r\n    - [ ] [The Pragmatic Programmer](https://www.amazon.com/Pragmatic-Programmer-Journeyman-Master/dp/020161622X)\r\n    - [ ] [Code Complete: A Practical Handbook of Software Construction](https://www.amazon.com/Code-Complete-Practical-Handbook-Construction/dp/0735619670/ref=pd_lpo_sbs_14_t_1?_encoding=UTF8&psc=1&refRID=K75WSC0JK6J62XWX4AHR)\r\n    - [x] [Real Programmers Don't Use PASCAL](http://web.mit.edu/humor/Computers/real.programmers)\r\n- [x] Work with a dataset larger than one petabyte\r\n- [x] Write your own ML model using nothing but a math library (numpy or equivalent)\r\n- [x] Throw away code for a project and start from scratch\r\n- [ ] Work in an open-space environment\r\n- [x] Work in an office/cubicle environment\r\n- [x] Work for a tech giant\r\n- [ ] Work for a startup with < 10 engineers\r\n- [ ] Work as a manager for a dev team\r\n- [ ] Write your favorite game in any language\r\n- [x] Write a mobile app specifically for one platform\r\n- [ ] Write a cross-platform mobile app\r\n- [ ] Work as a freelancer\r\n- [ ] Teach a kid to code\r\n- [x] Teach a class on programming\r\n- [ ] Write and publish a technical book\r\n- [ ] Receive a job offer without an interview\r\n- [ ] Publish a technical tutorial\r\n- [ ] Answer a question on StackOverflow\r\n- [ ] Have an answer upvoted 100+ times on StackOverflow\r\n- [ ] Write a program using strictly Vim or Emacs in the terminal\r\n- [ ] Write a non-trivial program in:\r\n    - [x] C\r\n    - [x] MIPS\r\n    - [ ] Go\r\n    - [x] C++\r\n    - [x] C#\r\n    - [x] Node.js\r\n    - [x] TypeScript\r\n    - [x] Python\r\n    - [x] Java\r\n    - [x] Android\r\n    - [ ] Swift\r\n    - [ ] Rust\r\n    - [ ] Elixir\r\n    - [ ] Scala\r\n- [ ] Write a program in a functional language\r\n- [x] Write a program for a robot\r\n- [ ] Work on software that requires government clearance\r\n- [ ] Infiltrate a large system undetected\r\n- [ ] Place top 5 in a Kaggle competition\r\n- [x] Write a blog about your career "
  },
  "Joining Microsoft": {
    "name": "JoiningMicrosoft.md",
    "content": "---\r\ntitle: Joining Microsoft\r\ndate: 2018-6-1\r\n---\r\n\r\nI've had a few friends ask me what my journey to Microsoft was like and why I chose to work here. Microsoft, like the Yankees and black licorice, is one of those \"love it or hate it\" kind of things (I fall emphatically into the latter camp for both of those other two). Everyone has reasons or experiences that make them feel one way or the other. As for myself, I've really enjoyed working at Microsoft, so I thought I'd document a little bit of my journey and why I ended up where I did.\r\n\r\n## The Interview\r\n\r\nI first interviewed with Microsoft in 2015 for a summer internship. When they called me and asked me to fly out for a round of final interviews in Redmond, my wife and I saw it as a free trip to Seattle. In my head, I was nowhere near qualified to work at a place like that and had all but written myself off from the start. The [Imposter Syndrome](https://en.wikipedia.org/wiki/Impostor_syndrome) was as real as ever. But I had promised my wife earlier that year that I would take us some place out of Utah that summer for an internship of some kind, so I really did want it to work out.\r\n\r\n![alt text](/resources/images/Microsoft/sign.jpg)\r\n\r\nI didn't feel great about my interviews - a couple of them felt downright terrible. But I did try hard to explain my thought process and walk my interviewers through my solutions to the problems they presented. \r\n\r\nAfter our brains had become sufficiently scrambled through the 4-hour interview process, the recruiters took us to lunch at the Commons. When we came back from lunch, they handed out Microsoft hoodies and swag (pretty much a participation trophy for interviewing, but **score** nonetheless). I was just about to head out the door to go back to the hotel, intent on enjoying the rest of the weekend in Seattle with my sweet wife, when one of the recruiters pulled me aside.\r\n\r\nWe went into a nearby conference room with one of the other recruiters, where they explained that they had an offer on the table for me. Shock doesn't begin to describe what I was feeling. It was cool to see that they were genuinely excited for me. I think they were even more excited for me to tell my wife. \r\n\r\nOn principle, I wouldn't officially accept anything until I had talked to Kate first, so I told them I would send them an email later that day. I called Kate as soon as I left the building and could barely contain my excitement as I tried to explain what just happened, not really knowing the answer myself. We spent the night in downtown Seattle, fully able to relax and imagine what our summer would be like in this new place.\r\n\r\n![alt text](/resources/images/Microsoft/seattle.jpg)\r\n\r\n## A New Intern\r\n\r\nThe day after I took my last final in May of 2016, we packed up our Highlander with everything we'd need for the next 3 months and made the 12-hour drive to our summer home. Microsoft put us up in an apartment in Redmond, which was close enough to one of the buildings that I could schedule a shuttle to pick me up and take me to the office. I became friends with many of the shuttle drivers I met that summer and remain very close friends with a few of them to this day. I've been to dinner with them, attended funerals of family members, and even stayed in one of their houses while I was looking for a place to stay for my family. Some of the finest people I've ever had the chance to meet.\r\n\r\nI spent that first summer in building 109 of Microsoft's campus, working with the WDG Global Services Localization Data Insights team (kind of a mouthful). My project was to automate the process by which our team identified meaningful feedback, particularly when it came to localization issues in Windows. I was able to work with a few teams across Microsoft to create a system that utilized an internal big data platform and natural language processing/machine learning tools to process and identify feedback most likely to be actionable in order to pass it along to developers. \r\n\r\n![alt text](/resources/images/Microsoft/project.jpg)\r\n\r\nIt solved a critical business need for the team, as they had previously been hiring sub-contractors to _read each piece of feedback, one by one_ and decide which ones were actionable. That may work for a smaller system, but for something like Windows, that's just not scalable. The project was a success, I learned a ton and had a blast doing it. For more detail on this project, check out my [blog post](/Microsoft-Summer2016/) written right after finishing for the summer. Of course, I enjoyed the many intern events and parties held for us... A private Ellie Goulding concert at the Space Needle where they hand out new Surface Books at the end wasn't anything to sneeze at... But the highlight for me was the learning and growing I was able to do, being surrounded by an amazing group of talented individuals that didn't mind taking the time to teach and mentor an intern.\r\n\r\n![alt text](/resources/images/Microsoft/team.jpg)\r\n\r\nI accepted an offer to return to the same team the following summer. As these things go, there was a massive re-organization within the team, my manager left Microsoft to pursue a personal dream of civic engagement as the City of Seattle's new Open Data Program Manager, and I would be reporting directly to my previous skip-manager. Although I was very sad to hear my manager would be leaving, I was happy to still be working under someone I knew and respected a great deal. \r\n\r\n## Return of the Intern\r\n\r\nOur journey back to Redmond after a long school year was pretty much the same, aside from one major detail - my wife was 6 months pregnant. She was due on August 10th, just 13 days after I was scheduled to finish my internship. Microsoft was _extremely_ accomodating with us. They put us in an apartment that was literally a 6-minute bike ride from building 109. They told me that if anything came up, I should feel free to take time to be with her and not to worry about work. My recruiters even got us a bag of gifts for the baby from the Microsoft store. We really felt that they had our interests at heart and cared about our little family.\r\n\r\n![alt text](/resources/images/Microsoft/baby.jpg)\r\n\r\nMy project during that second summer was very broad, more of a question to answer with no real guidance given on the implementation. I was free to take the project in whatever direction I saw fit. The question was \"How do we identify influential communities of Windows users/devices so that we can weight their feedback more heavily?\" These communities went much deeper than just \"gamers, business users, mobile users, etc.\" We already knew that for most devices. I wanted to find a way to use Windows telemetry to cluster devices together that actually *behaved* in a similar way, so that we could amplify the voice of Windows Insiders (users that receive Windows versions before they are released to the public) that more accurately represented that population.\r\n\r\nAt a 30,000 foot level, my approach was fairly straight forward: run k-means clustering on Windows devices within a locale (primary language used on device) and assign each device a score proportional to the size of the cluster and inversely proportional the device's distance from the centroid (higher score = big cluster and close to center). The problem became finding ways to run this efficiently on pedabytes of telemetry data and setting it up to run in an automated workflow. The systems we used had a timeout of 2 hours when running a script, so in order to give it time to finish, I was forced to break it up into smaller chunks of data and run many smaller scripts in parallel.\r\n\r\nThe project went well, and laid a foundation for future work in the area. But as with any probabilistic problem (especially when dealing with unsupervised learning), it's difficult to know when you've found the right approach. Testing your solution can be just as hard as developing it in the first place. When it came down to it, 12 weeks just wasn't a lot of time to understand the problem, map out a solution, implement it by myself and verify the results. And when I say \"by myself,\" that's not to say I didn't receive a lot of help throughout the process. I just mean that no one else was _directly_ working on the project with me. I'm confident that given a few more months, we would have come up with a solid approach to answer this question.\r\n\r\n## The Decision\r\n\r\nAt the end of the summer, I had some difficult decisions to make - whether or not to stay at Microsoft and, if I did stay, whether or not to stay with my current team. I really had enjoyed working with these people for the past two summers. I had learned a lot and was sure there was more to learn from them. But I also felt like broadening my horizons and looking at what other teams/companies had to offer. Two of the main things I was looking for were opportunities to challenge myself and grow, as well as a family-friendly atmosphere.\r\n\r\nThroughout the summer, I had been trying to follow the advice of mentors to keep my options open, so I interviewed with several different companies and had informationals with several teams across Microsoft. In that process, I discovered the Partner Catalyst Team, whose charter was basically to code with Microsoft partners on whatever they were building, which often times included contributing to open-source projects and traveling around the world. I met with a couple of the managers from the team, and even jumped on a Hackathon project with one of them as a little test run of what it would be like to work with them. I had a *great* time and learned a lot in the 3 days we worked together.\r\n\r\nWe went home for the summer. I was still talking to and interviewing with several different companies around the West, including leaving my poor wife while she was 8.9 months pregnant to fly to Silicon Valley. After weighing a few options, thinking about what was best for our family and where I could grow the most, I chose to stay at Microsoft, but switch to this new team. Both my wife and I thought this was the right call and we were ecstatic.\r\n\r\nI went to school and finished my last semester, graduating in December of 2017 and returning to Microsoft on January 8th of 2018. The team had been re-organized and renamed as Commercial Software Engineering (CSE), and I'd be specifically working with the Digital Win Room team within that organization. I spent a week with the team, and then took 2 of the 3 available months of paternal leave, which I was able to use at any time before our new son Jack's birthday in August. I couldn't believe how understanding they were and that the team was happy to let me take that time to get the family moved and spend time together before really starting at work.\r\n\r\nI've been officially back for just about 3 months now, and I have had a blast with some really cool projects and fun adventures. I'll do my best to keep the blog updated on the happenings here.\r\n\r\nSo, there you have it. I joined Microsoft because I felt like it would be a place where I could grow as a Software Engineer and, even more importantly, as a husband and father. I stay because those things are still true. \r\n\r\nIf you have any other questions about what it's like to work here, feel free to reach out via any of the communication channels below!"
  },
  "Microsoft - Summer 2016": {
    "name": "MicrosoftSummer2016.md",
    "content": "---\r\ntitle: Microsoft - Summer 2016\r\ndate: 2019-9-2\r\n---\r\n\r\nIn 2016, I had the opportunity of working with the WDG GS Data Insights team at Microsoft. While there, I was given the task of automating the process of taking action on international customer feedback. Because Windows 10 gets such a high volume of feedback from its users, a lot of valuable information sits idly in a database without anyone being able to act on it. Of course, there is always a lot of junk to sift through and LOTS of duplicated pieces of feedback, which made the challenge of automating the process even more interesting.\r\n\r\nI was privileged to work with teams and individuals across Microsoft, many of whom were quite a few pay grades ahead of us lowly interns. One of my absolute favorite parts of my internship was the aspect of collaboration. As my all-time hero once said, \"It's amazing how much can be accomplished when no one cares who gets the credit.\" (John Wooden) While I understand and agree that everyone deserves credit for their work and accolades for a job well-done, I also feel that there is something to be said for those synergistic teams that are able to feed off of one another and do something great because they are more focused on the thrill of the project than their own career advancement.\r\n\r\nI was grateful for my Database Systems course I had taken the previous semester, because I was able to help optimize the database being used. Previously, some of the queries took over a minute (sometimes more) to process. After some of our optimizations, those queries were running in 2 seconds or less.\r\n\r\nIn order to identify actionable feedback and filter out those that had nothing , I worked with a team that has spent the last 2.5 years developing an internal text analytics engine that could help do just that. I met with their team lead on an almost-weekly basis to discuss needs of the project and even help them debug their solution. It was a great partnership and I was grateful for all of their help.\r\n\r\nI also worked with several web technologies, as bugs and Work Items are housed in Visual Studio Online. In order to pass actionable feedback onto developers, I needed a Restful Web Api that I could call to \"promote\" such a bug. Thankfully, there was another team of very helpful individuals that managed that Api, and that ended up being the easiest part of the project.\r\n\r\nEven after launching our first batch of auto-promoted bugs, the system was not perfect. There were still a few pieces of feedback that probably should not have been promoted, but to give you some perspective, our first batch was only 131 promoted bugs out of 10M+ pieces of feedback sitting in the database. The filtering was not perfect, but it was a start.\r\n\r\nThe rest of the summer was spent trying to refine the process. I worked with teams of native-language speakers to identify the original translation of each feedback to determine the meaning. One of the great eye-openers during this process was the discovery of how difficult machine translation really is. It's an incredibly fascinating problem, but one that seems to have no perfect solution... yet.\r\n\r\nI've accepted an offer to return to the same team for another internship next summer, where I'm told I might be working on helping to improve machine translation. I'm still not sure in what capacity that will be, but I'm just excited to be a part of it.\r\n"
  },
  "NBA Position Clustering": {
    "name": "NBAclustering.md",
    "content": "---\r\ntitle: NBA Position Clustering\r\ndate: 2017-4-8\r\n---\r\nPlayer positions in the NBA have become a rather fluid concept. Teams like the Warriors with their \"Lineup of Death\" have shaken the traditional mindset of the basketball world. We wanted to be able to build out a clustering model that used a player's statistics to identify the player's \"true position.\" When we say \"true position,\" we mean the position the player plays most alike. While LeBron James could be listed at just about any position on the floor, we wanted to know what his stats told us. By creating an unsupervised clustering model, players would be grouped together with other players of a similar statistical model.\r\n\r\n<iframe width=\"800\" height=\"600\" src=\"https://app.powerbi.com/view?r=eyJrIjoiODgzZjhiMmQtYmU5My00NzM4LTk1MjUtNWVhYWUzM2RiYzhlIiwidCI6Ijg0YzMxY2EwLWFjM2ItNGVhZS1hZDExLTUxOWQ4MDIzM2U2ZiIsImMiOjZ9\" frameborder=\"0\" allowFullScreen=\"true\"></iframe>\r\n\r\n## Introduction\r\n\r\nOur Data Mining project was based on looking for statistical groupings in the National Basketball Association that define the different positions in the modern game of basketball. In basketball, often a given position becomes an argument for what will and won’t work on a roster, when it’s really much more complicated than that. We want to define the numbers behind what a guard, forward, wing or center is, as well as look for outliers, such as forwards performing statistically equivalent to guards. \r\nThe key idea to our project was that there is more to a player than his labeled position. As the NBA has changed in the modern game, there has been a tendency to ‘play small’ as popularized by the Golden State Warriors infamous ‘Lineup of Death’. Examples like these have shown that players longtime slotted into a single position are actually more flexible, and possibly more effective, when placed somewhere completely new. Our goal was to use clustering methodology to look for what defines each of the four positions and search for specific groups of players, as well as outliers, in order to view the game differently. Our graphs have been created using Power BI, an interactive data visualization tool, and we strongly recommend opening the dashboard side by side while reading this paper. It can be found at [this link](https://app.powerbi.com/view?r=eyJrIjoiODgzZjhiMmQtYmU5My00NzM4LTk1MjUtNWVhYWUzM2RiYzhlIiwidCI6Ijg0YzMxY2EwLWFjM2ItNGVhZS1hZDExLTUxOWQ4MDIzM2U2ZiIsImMiOjZ9). \r\n\r\n## Data Wrangling and Cleaning\r\n\r\nFor our project, we used individual statistics of players from the 2010 - 2016 seasons in the NBA, which we obtained from https://probasketballapi.com/. The data didn’t turn out to be perfect and required several rounds of cleaning and refining in order to produce something worth using. To start, there were several non-basketball athletes in the data set, many players were minimum impact competitors who hardly played and didn’t last very long in the NBA, and some categories, like position, were labeled in an extremely haphazard manner. For example, a player could easily be labeled as a Guard, Point Guard, Shooting Guard, Point Guard/Shooting Guard or Shooting Guard/Point Guard with no distinction as to why any particular choice was made. In order to give a wide range of options, we ran our simulations over statistics gathered from each season, as well as an averaged statistical output from the entire 2010 - 2016 data set.\r\n\r\nIn cleaning our data, we eliminated all non-basketball players, required that a player has played at least 20 games and averaged at least 10 minutes played per game. To normalize the position labels and make up for a lack of distinction between some positions, we organized the athletes into four basic positions. “Guard” consists of players labeled Guard, Point Guard or capable of playing Point Guard or Shooting Guard. “Wing” consists of Shooting Guards (only 3 players in the whole dataset labeled as such), hybrid Guard/Forwards and Small Forwards. “Forward” consists of hybrid Small and Power Forwards and pure Power Forwards. And “Center” is our big man group, consisting of hybrid Power Forward/Centers and Centers. While originally, we only had three positions defined, looking at the numbers in the many categories provided by our data source, we felt these four categories most naturally used the distribution to create a good foundation for our analysis and represented the current state of NBA tactics. One of the difficulties in identifying effective clustering measures was the skew in number of players for each position. This is shown in the already-large and increasing number of guards, as depicted below.\r\n\r\n![alt text](/resources/images/nba-1.png)\r\n\r\nThis increase of smaller players seems to agree with the rest of our analysis, as the league is trending towards players who can score from long range as opposed to the traditional, “inside-out” philosophy, but it adds to the challenge of finding effective clustering measures.\r\n\r\n## Initial Analysis\r\n\r\nWe began our analysis by doing simple comparisons among the four positions we had identified. We compared the averages of the box score statistics, the advanced statistics and some of the shot chart statistics to look for simple ways in which the positions differentiated themselves. Some graphs are shown here, but for full size and interactivity for all graphs, please see our [dashboard](https://app.powerbi.com/view?r=eyJrIjoiODgzZjhiMmQtYmU5My00NzM4LTk1MjUtNWVhYWUzM2RiYzhlIiwidCI6Ijg0YzMxY2EwLWFjM2ItNGVhZS1hZDExLTUxOWQ4MDIzM2U2ZiIsImMiOjZ9).\r\n\r\n\r\n![alt text](/resources/images/nba-2.png)\r\n\r\n\r\n![alt text](/resources/images/nba-3.png)\r\n\r\n\r\n![alt text](/resources/images/nba-4.png)\r\n\r\n## Clustering\r\n\r\nWe began with clustering our dataset using both hierarchical clustering with single-link distance metrics and assignment-based clustering using k-means++ and Lloyd’s algorithm. We originally used Gonzalez’s as well but found it less effective and switched our comparisons to single-link and k-means++. For both algorithms, we clustered the data from k = 3 to k = 8, using every combination of 7 statistical feature sets for each player: box score, advanced statistics, shot zone, shot range, shot area, action type and shot type. We ran assignment-based clustering for larger values of k, but with the amount of time required to run single-link hierarchical clustering, we limited our comparison from k = 3 to k = 8. Even with the limited scope, this resulted in almost 10,000 different clusterings with no simple way to identify which were better suited for our purposes. In order to find which clusterings best represented our chosen positions, we began searching for “polarity” among the results. We define “polarity” for a group of clusters as the average percentage of the dominant position for each cluster. Ideally, we would want a group of clusters to have a polarity of 100%, which would mean each cluster would consist entirely of one position.\r\n\r\n## Results\r\n\r\nThe first thing we found is that hierarchical clustering with single-link did not perform as well as we thought. We had anticipated that single-link would do well in linking the most statistically similar players one at a time and that this would lead to a more linear clustering of players. What it actually did, in most cases, was produce (K - 1) singleton clusters and 1 large cluster of the rest of the players. This lead to it getting great scores on our polarity tests, because a cluster consists of only 1 or 2 players, it’s pretty easy to get a cluster of 100% the same position. The variation in cluster size is shown in the graph “Cluster Size Standard Deviation.” While not especially valuable for clustering, it was interesting to see the algorithm identify the game’s “superstars” (Russell Westbrook, Lebron James, Kevin Durant, etc.). We then decided to programmatically prioritize cluster sets that had larger chunks of one position in each collection and focus solely on k-means++ assignment-based clustering for our results.\r\n\r\n![alt text](/resources/images/nba-5.png)\r\n\r\nIn the end, our polarity methods determined that the best clustering result was using Lloyd’s algorithm with k-means++, clustering on box score, advanced statistics, shot range (Less than 8 ft., 8-16 ft., 16-24 ft., 24 ft.+), action type (pull-up jumper, alley-oop dunk, etc.) and shot type (2 pt. vs. 3 pt.) for the 2013 season data set where k = 7.\r\n\r\n![alt text](/resources/images/nba-6.png)\r\n\r\nIn figure 5, you can see the basic results of our determined best clustering, organized by position and each cluster’s size. We call cluster 1 the “Attack the Rim” cluster. It consists of high volume inside shooters like Derrick Rose, Kobe Bryant, Brook Lopez and JaVale McGee. It’s interesting to see how this clustering put players in very different positions into the same grouping. Cluster 2 is our “True Point Guards” (traditional, pass-first) collection, with Rajon Rondo, Jrue Holiday, Steve Nash and Eric Bledsoe leading the way. Cluster 4 is referred to as our “Spot-up Shooters” cluster, consisting of high volume outside shooters like Jimmer Fredette, Brandon Rush, CJ McCollum and Jason Terry. Players who are known more for their ability to shoot from the floor, and are most likely subpar defenders. Cluster 7, which we call the “6th Man Cluster”, is another intriguing look. It is full of guards known for high scoring and utility in limited minutes. Matthew Dellavedova, J.J. Barea, Jeremy Lin, Patrick Beverley, Lou Williams, Jerryd Bayless, Shelvin Mack, Iman Shumpert and even Andre Miller are all sorted here.\r\n\r\nWhile these little itemizations are fun, overall, we learned a great deal from this project. The first thing we learned was that more data is not inherently good thing. The more parameters you input, the more confounding and confused your results can become. As your results become harder to visualize, it’s difficult to tell if your results actually mean anything. Clustering is also a difficult problem, and the methodology you decide on at the beginning heavily affects your results. In our quest to determine positional outliers, we also had tremendous success. One example is our “6th Man Cluster”. While being primarily guards, an outlier is the inclusion of Andre Iguodala. Though this is based on the 2013 data set, it feels reminiscent of Iguodala’s run as a key playmaker in Golden State’s aforementioned ‘Lineup of Death’. His ability to play a role far from his position title led to his naming as Finals MVP in Golden State’s championship. Looking to the future, similar clusterings on the 2016 data set have us extremely interested in the futures of Sam Dekker, Kelly Oubre Jr. and Myles Turner. It becomes even more difficult to cluster over a career when taking into consideration the evolution of each player’s style of play. One of the most well-known examples of this was Michael Jordan’s shift from the high-flying dunk virtuoso that he was when he entered the league to the clutch scorer from mid-to-long range that he became near the end of his career. We don’t think the NBA has ever been as simple as slotting 5 players into position on the floor. And it’s only going to get more interesting.\r\n\r\n## Future Work\r\n\r\nIn order to narrow the scope of this project, we chose to cluster based on groups of statistics (box score, advanced, shot type, etc.) rather than individual statistics themselves. This is partly for our own sanity in trying to keep track of 123 different statistical measures for each player over the span of 6 NBA seasons, but mostly because of the combinatorial nightmare that would arise when trying to find effective combinations of statistics for high accuracy in clustering players based on position. Given the time and resources, we would like to run all possible combinations of those stats, or at least a reasonable amount of those combinations, to see if we can fine-tune our view about which statistics really are indicative of position, how those positions change and evolve over time and how the game is influenced by this position fluidity."
  },
  "Personal Informatics Time Tracking Experiment": {
    "name": "PersonalInformatics.md",
    "content": "---\r\ntitle: Personal Informatics Time Tracking Experiment\r\ndate: 2017-3-6\r\n---\r\n\r\nFor one of my courses at the University of Utah, we did an experiment where we logged everything we did during a specified timespan. We then compared our personal data with those of the participants in the [2014 ATUS Experiment](https://www.bls.gov/tus/datafiles_2014.htm). These are my findings, presented in a visualization with Power BI:\r\n\r\n<iframe width=\"800\" height=\"600\" src=\"https://app.powerbi.com/view?r=eyJrIjoiNGJjNzEwZTMtYWJhZi00MGYwLTk1ODUtOWQwZjA2NDdjZTQxIiwidCI6Ijg0YzMxY2EwLWFjM2ItNGVhZS1hZDExLTUxOWQ4MDIzM2U2ZiIsImMiOjZ9\" frameborder=\"0\" allowFullScreen=\"true\"></iframe>\r\n"
  },
  "Top 5 (unordered) Learnings from PyCon 2019": {
    "name": "Pycon2019.md",
    "content": "---\r\ntitle: Top 5 (unordered) Learnings from PyCon 2019\r\ndate: 2019-5-6\r\n---\r\n\r\nThis is a summary of 5 of my favorite talks from PyCon 2019. I learned a ton throughout the conference and felt that the learnings needed to be shared. I've tried to summarize as best as I could from the notes that I took. I believe the talks will be available online soon if they are not already. Big thanks to the speakers for all the effort they put in to make their talks so practical and engaging.\r\n\r\n## Black Swans - Keynote from Russell Keith-Magee\r\n  \r\n  This was the first keynote of the conference, and it was **awesome**. Mr. Keith-Magee discussed the [black swan theory](https://en.wikipedia.org/wiki/Black_swan_theory), which, as a very crude summary, are things that seem obvious in hindsight but that no one had thought of previously. \r\n  \r\n  He tied that to the 1983 America's Cup winning sailing team from Perth, Australia, and their use of the [winged keel](https://en.wikipedia.org/wiki/Winged_keel). This innovation helped their boat move with less resistance. Sailboats had been roughly the same for the previous few decades and teams that failed to innovate were left behind. He invited us to challenge our assumptions and to look for \"black swan\" innovations, particularly relating to the open-source and Python communities.\r\n\r\n## Break the cycle: three excellent python tools to automate repetitive tasks - Thea Flowers\r\n\r\n#### 1. `tox`\r\n    \r\nOne of the most common tools used in Python applications. Used to run tests in multiple environments and even multiple versions of frameworks. For example if you want your app to support multiple versions of Python and multiple versions of Flask, your `.ini` file could look something like (example taken from the `flask-restful` repo):\r\n    \r\n~~~ \r\n[tox]\r\nenvlist=\r\n    py{27,34,35,36,37}-flask{0_10,0_12,10}\r\n\r\ndeps =\r\n    flask0_10: flask>=0.10,<0.11\r\n    flask0_12: flask>=0.12,<1.0\r\n    flask10:   flask>=1.0,<1.1\r\n\r\n[testenv]\r\nusedevelop = true\r\ncommands =\r\n    pip install -e .\r\n    nosetests\r\ndeps =\r\n    -r{toxinidir}/tests/requirements.txt\r\n~~~ \r\n\r\nWhen the command `tox` is executed, this would run the test suite **15 times** (cross product of Python environments and Flask versions - `5 x 3 = 15`). As part of that process, it would install the necessary dependencies in virtual environments (according to each version) and run the tests. Pretty cool.\r\n\r\n#### 2. `nox`\r\n    \r\nPretty cool to listen to a talk from the original `nox` author. `nox` is very similar to `tox`, but rather than using the `.ini` file, its configuration is done in Python itself. The `nox` equivalent to the `tox.ini` file above would be something like:\r\n\r\n~~~ python\r\n@nox.session(python=['2.7', '3.4', '3.5', '3.6', '3.7'])\r\n@nox.parameterize('flask', ['0.10', '0.12', '1.0'])\r\ndef tests(session, flask):\r\n    # Install pytest\r\n    session.install('pytest')\r\n    # Install version of flask\r\n    session.install(f'flask=={flask}')\r\n    # Install everything in requirements-dev.txt\r\n    session.install('-r', 'requirements-dev.txt')\r\n    # Install the current package in editable mode.\r\n    session.install('-e', '.')\r\n    # Run pytest. This uses the pytest executable in the virtualenv.\r\n    session.run('pytest')\r\n~~~ \r\n\r\nAlso a really cool option, which is helpful if you need something slightly more flexible than `nox` or if you'd rather write config-as-code.\r\n\r\n#### 3. `invoke`\r\n\r\nInvoke is seen as a more flexible automation tool. For example (straight from `invoke`'s docs):\r\n\r\n~~~ python\r\nfrom invoke import task\r\n\r\n@task\r\ndef clean(c, docs=False, bytecode=False, extra=''):\r\n    patterns = ['build']\r\n    if docs:\r\n        patterns.append('docs/_build')\r\n    if bytecode:\r\n        patterns.append('**/*.pyc')\r\n    if extra:\r\n        patterns.append(extra)\r\n    for pattern in patterns:\r\n        c.run(\"rm -rf {}\".format(pattern))\r\n\r\n@task\r\ndef build(c, docs=False):\r\n    c.run(\"python setup.py build\")\r\n    if docs:\r\n        c.run(\"sphinx-build docs docs/_build\")\r\n~~~ \r\n\r\nwhich is run by calling:\r\n\r\n~~~ bash\r\n$ invoke clean build\r\n~~~ \r\n\r\nThis can be very useful even outside of things like Python testing. Planning on converting some of the scripts I use on my machine to `invoke` commands.\r\n\r\n## Wily Python: Writing simpler and more maintainable Python - Anthony Shaw\r\n  \r\nThis talk was definitely one of my favorites. We had just talked a lot about code complexity when working on [VoTT](), and not many of us knew exactly how that was calculated. Anthony talked about three different ways to measure code complexity and how all of them play a factor in calculating the \"maintainability index\".\r\n\r\nThe first, most crude way of measuring complexity is by **lines of code**. Fewer lines *can* be less complicated, but in a language like Python, you could have a one-liner like this function for the Sieve of Eratosthenes:\r\n\r\n~~~ python\r\ndef sieve_eratosthenes(n):\r\n    return sorted(set(range(2,n+1)).difference(set((p * f) for p in range(2,int(n**0.5) + 2) for f in range(2,(n/p)+1))))\r\n~~~ \r\n\r\nAnother measure is by **cyclomatic complexity**, for which he gave the example of ordering a Big Mac:\r\n\r\n~~~ \r\nCASHIER: What would you like?\r\nME: I'd like a Big Mac please\r\nCASHIER: Make it a meal?\r\nME: Sure\r\nCASHIER: Small, large or super size?\r\nME: Large\r\nCASHIER: What would you like to drink?\r\nME: Coke\r\nCASHIER: Diet or regular?\r\nME: Regular\r\n~~~ \r\nJust in that interaction, the cyclomatic complexity would be **5**, which is basically *the number of decisions that need to be made*. In Python, things like `if`, `elif` and `try` are things that increase cyclomatic complexity.\r\n\r\nThis is why you might get asked in a code review to \"invert `if` statement to reduce nesting.\" The phrase *\"flat is better than nested\"* is directly from the Zen of Python (discussed more below) and explained in the famous email to the Python mailing list [Why \"flat is better than nested\"?](https://mail.python.org/pipermail/python-list/2010-October/590762.html).\r\n\r\nWhere the code complexity measurement gets more \"mathy\" is when we start talking about Halstead Complexity measures. I won't go too deep into this, but it involves operators, operands, sums of each and much more.\r\n\r\nWhen you combine these three measurements, you can calculate the `maintainability index` as such:\r\n\r\n~~~ \r\nMI = 171 - 5.2 * ln(Halstead Volume) - 0.23 * (Cyclomatic Complexity) - 16.2 * ln(Lines of Code)\r\n~~~ \r\n\r\nThere have been variations of this original formula, which you can read about [here](http://www.projectcodemeter.com/cost_estimation/help/GL_maintainability.htm)\r\n\r\nAfter discussing the theory behind all of this, Mr. Shaw introduced the Python utility he wrote called `wily`, which you can install on pip. `wily` is \"A command-line application for tracking, reporting on complexity of Python tests and applications.\" Definitely planning on using `wily` in my next Python project!\r\n\r\n## The Zen of Python Teams - Adrienne Lowe\r\n  \r\nMany people are familiar with \"The Zen of Python\" as laid out in an email from Tim Peters and described on python.org as \"guiding principles for Python's design into 20 aphorisms, only 19 of which have been written down.\" (meaning the 20th is something for us as a community to fill in for ourselves)\r\n\r\nHere are the 19 aphorisms:\r\n\r\n~~~ \r\nBeautiful is better than ugly.\r\nExplicit is better than implicit.\r\nSimple is better than complex.\r\nComplex is better than complicated.\r\nFlat is better than nested.\r\nSparse is better than dense.\r\nReadability counts.\r\nSpecial cases aren't special enough to break the rules.\r\nAlthough practicality beats purity.\r\nErrors should never pass silently.\r\nUnless explicitly silenced.\r\nIn the face of ambiguity, refuse the temptation to guess.\r\nThere should be one-- and preferably only one --obvious way to do it.\r\nAlthough that way may not be obvious at first unless you're Dutch.\r\nNow is better than never.\r\nAlthough never is often better than *right* now.\r\nIf the implementation is hard to explain, it's a bad idea.\r\nIf the implementation is easy to explain, it may be a good idea.\r\nNamespaces are one honking great idea -- let's do more of those! \r\n~~~ \r\n\r\n(If you didn't know, these are in a Python Easter Egg. Fire up `python` in your terminal and type\r\n    \r\n~~~ \r\n>>> import this\r\n~~~ \r\nto see what I mean.)\r\n\r\nThese sayings are usually applied directly to the code that we write, but Adrienne Lowe discussed how we can take some of these principles and apply them directly to how we work within our teams. Here are a few that she discussed:\r\n\r\n#### \"Beautiful is better than ugly\"\r\n\r\nWe can avoid \"acting ugly\" with our teammates. \"Acting ugly\" can come in the form of bitter, cutting code reviews, hoarding information and refusing to collaborate with others.\r\n\r\nShe referenced Westrum's [\"A typology of organisational cultures\"](https://qualitysafety.bmj.com/content/13/suppl_2/ii22), which discusses three different types of cultures in a team:\r\n\r\n###### 1. Pathological\r\n- Information is a **personal** resource (not to be shared)\r\n- Cooperation is discouraged\r\n- Failure leads to scapegoating\r\n- Accidents lead to blaming\r\n\r\n###### 2. Bureaucratic\r\n- Responsibilities are narrow\r\n- Alignment of team takes precedent over mission\r\n- Failure leads to seeking justice\r\n- Novelty leads to problems\r\n- Maintain turf\r\n- Insist on being done by the book - their book\r\n- Inter-team dynamics neglected\r\n\r\nThis one reminded me immediately of the old cartoon depicting Microsoft's organizational culture-of-old:\r\n\r\n![alt text](https://dougbelshaw.com/blog/wp-content/uploads/2013/09/organizational_charts.png)\r\n\r\nThankfully, I can say that in my ~2 years working for Microsoft, I have yet to experience that kind of culture. Things have changed :)\r\n\r\n###### 3. Generative (the goal)\r\n- High cooperation\r\n- Risks are shared\r\n- Failure leads to inquiry\r\n- Information flows freely\r\n- How can we accomplish our goal (\"we\" is expansive and inclusive of all)\r\n\r\n#### \"Explicit is better than implicit\"\r\n- We should *always* have playbooks, documents, resources, onboarding guides and steps to take when confused\r\n- Having these in place and other process documentation makes it easier to include others and speeds up the work\r\n- It is better to keep conversations about code in **main channels** of Slack or whatever messaging service you use as opposed to DMs or other private places. Helps everyone benefit from the knowledge being shared\r\n- Documenting process also improves relationship between teams\r\n- We should **document our people**\r\n    - I enjoy working on...\r\n    - I get excited by...\r\n    - I struggle when...\r\n    - I feel appreciated when...\r\n    - I prefer feedback...\r\n    - Ask me for help with...\r\n- Helps with process of working within teams an can be extremely valuable\r\n\r\n#### \"Simple is better than complex\"\r\n- We build meaningful relationships with small interactions that increase understanding and trust\r\n- Take time to have coffee with colleagues, catch up on weekend, etc.\r\n- **Remote teams** -> Remote Happy Hours - just jump on a video call to chat about lives\r\n- Build trust and familiarity with colleagues\r\n- Like software, we build relationships with small but meaningful actions\r\n\r\n#### \"Errors should never pass silently\"\r\n- If something is wrong with my code, I want to know\r\n- If I do something to hurt someone, I want to know\r\n- We rely on other humans to know that we hurt them\r\n- Feedback is the tool we have to understand our impact on others\r\n- On healthy teams, people should understand what things they need to do to improve\r\n- Be careful about how you respond about mistakes. We all need to be open about mistakes and willing to \"share our trash\" to the point that we're not self-conscious about getting feedback from others.\r\n\r\n#### \"In the face of ambiguity, refuse the temptation to guess\"\r\n- Don't `git blame` and stew about it\r\n- Assume the best and don't guess at motives.\r\n- Ask where they're coming from and try to understand why they did what they did\r\n- Be assertive\r\n- Open issues, comment on PRs\r\n- Challenge directly but care personally\r\n- Don't explain away code... or people\r\n- Especially for managers. Don't guess about how your direct reports are doing. You should know.\r\n\r\n#### \"Now is better than never\"\r\n- Take **some** action to move closer to our goal\r\n- \"Doing and being wrong is a lot better than not doing at all\"\r\n- Everyone benefits from being reminded that they can start where they are\r\n- **Challenge** - Fill in the 20th line of the Zen and share it on social media with `#HereYaGoGuido`\r\n\r\n\r\n## Type hinting and `mypy` - Bernat Gabor\r\n\r\n- Why use types in Python? Why not just use Java/C#?\r\n  - Makes code easier to:\r\n    - understand\r\n    - use\r\n    - maintain\r\n    - debug\r\n    - refactor\r\n  - Creates more accurate code suggestions\r\n  - Does lint checks that find bugs with no tests\r\n  - Improve documentation\r\n  - Built-in data validation\r\n  - Performance increase (sometimes)\r\n    - `mypyc` - Compiles c-extension type hinted code (not full syntax support yet), can lead to 4 to 20x performance improvement (due to the avoidance of hashtable lookups)\r\n- You can *gradually* introduce typings into your code (not all or nothing)\r\n- Typing example:\r\n~~~ python\r\ndef greeting(name: str) -> str:\r\n    s: str = name # You can add type annotations inline\r\n    return s\r\n~~~ \r\n- Gotchas\r\n  - If you have to maintain both Python 2 & 3, this will be difficult\r\n  - If you have mulitple return types, the best way to use typings will be to use the `@overload` decorator and declare the function multiple times\r\n  - Type lookup - looks for type in closest namespace\r\n    - For example, if you have a function named `float` that returns a `float` data type, it will type the return value as the function itself\r\n- Typing packages\r\n  - `mypy` - Reference implementation type checker\r\n  - `pyre` - Facebook\r\n  - `pytype` - Google\r\n  - `pyright` - Microsoft (fun fact - written in TypeScript)\r\n\r\n## Conclusion\r\n\r\nI hope this summary was of value to someone. Thank you again to the speakers and organizers of PyCon 2019.\r\n"
  },
  "The Difference - What Makes an Idea Work": {
    "name": "TheDifference.md",
    "content": "---\r\ntitle: The Difference - What Makes an Idea Work\r\ndate: 2018-6-15\r\n---\r\n\r\nWe've all been there. Talking with old friends or new acquaintances about your career as a software engineer, and those magical words pop into the conversation: \"_Bro... I have an idea for this app..._\" Much to the surprise and chagrin of many aspiring Zuckerbergs, success comes from a heck of a lot more than just a good idea.\r\n\r\nMy purpose here is not to disparage any idea. I think some of the best ideas in the world are those that sound insane from the start. My purpose is to reflect on one of my own experiences and use it to identify some of the things that separate the successful ideas from... well... the others.\r\n\r\n![alt text](/images/kramer.gif)\r\n\r\nThis experience I'm talking about was a time that I was able to witness the end-to-end process of an idea becoming a success. It started similarly to the other experiences I referenced in the beginning of this post - a friend came to me with an idea, and an ambitious one at that. \r\n\r\n_(cue [flashback music from \"Arthur\"](https://www.youtube.com/watch?v=KSm377MSv7Y))_\r\n\r\n## The Idea\r\n\r\nIt was April of 2016. I was just about to finish one of the most difficult semesters I'd had to date. I was trying to understand Turing machines, Database relational algebra, and every sorting algorithm ever made since the caveman stacked the biggest rocks at the bottom. For those of you who haven't experienced this, just imagine you're drowning... You cry out for help, hoping someone is close enough hear you... But the only response you get is from your terminal: `Segmentation fault`. \r\n\r\nIn the heat of the confusion, rage and tears, this friend approached me with an idea to create the biggest hackathon in the state of Utah. He wanted it to happen in the upcoming semester (in 5 months) and that he wanted me to help him do it. \r\n\r\nAt the time, I thought, _\"**How** could we ever do that? **Where** would we even find the time? **Why** put more on our plate than we already have?\"_ \r\n\r\nIt's safe to say I had my doubts. But after thinking about it for a few days, I thought it sounded kind of fun and that I'd join him. He recruited a few of our other classmates that were either crazy enough to say \"yes\" or too scared to tell him \"no.\" We had ourselves a team.\r\n\r\n## The Team\r\n\r\nOur first official meeting was a few weeks later, and was actually a video conference, as several of us were working at internships in different states. We jumped on the call and realized that none of us really knew any of the others, except for this friend that had pulled us into this. We weren't anti-social, but we each had our own spheres and didn't often venture outside them. \r\n\r\nI thought to myself, \"This is quite possibly the most random possible sampling of students in the University of Utah Computer Science program...\" Looking back, I realize that these were some of the first indications of differences between this idea and many of the others I'd heard:\r\n- **Assemble a *diverse* team** - Seriously, we could have been a poster for a University marketing campaign. We had just about every demographic covered. But diversity became much more than a box to check. A team with different backgrounds, perspectives, connections and opinions would become crucial to the success of the hackathon.\r\n- **Find the *right* people** - Rather than just pick his friends, he went out and picked people that would be right for each job and helped them catch the vision. I'm not saying the people on the team weren't his friends, but I think it's easy to fall into the trap of just defaulting to your circle of closest friends, even if they're not right for the job.\r\n\r\n## The Sacrifice\r\n\r\nI'll never forget the day we went to ASUU (Associated Students of the University of Utah), our school's student government, to ask for their financial sponsorship of our event. We came on a day where other clubs and student groups were being grilled by the student-legislators over requests in the $50-$100 range. We were coming in asking for $3,000. \r\n\r\nBut not only did we believe this event would be fun and impactful for each of the participants personally, we strongly felt it would benefit the University and the community in the long run. \r\n\r\nBig hackathons were starting to become one of the ways students from other schools in and out of the state were exposed to universities, and many of them would eventually plan on going to graduate school. We felt that if we could just give these students a chance to see what it's like to be at the University of Utah, more would consider the U for future educational opportunities.\r\n\r\nThese hackathons are also *major* opportunities for companies to recruit potential candidates (hence the corporate sponsors that shelled out $$$ for a booth at the event and their logo on our materials and website). If we could host a large event where students from around the state and country could get face time with local companies, it was possible that many of those participants would receive job offers, work in the area, and boost the local economy. \r\n\r\nSo, yes, $3000 from the University seemed like a lot up front, but we felt like the investment would pay for itself many times over.\r\n\r\nWhen we got up to pitch the idea to this group of our peers, many of them caught the vision, but there were also some that just couldn't get over the amount of money we were asking for. \r\n\r\nOne of them posed the question, *\"What will you do if you don't get the money?\"*\r\n\r\nMy friend answered without hesitation, *\"It will come out of my own pocket. I believe in this cause and it's something I'm willing to pay for if we don't get the funding.\"* I was as surprised as each of them. Which brings me to the next difference:\r\n\r\n- **Be willing to make *real* sacrifices** - It's not like he was made of money, either. He worked long hours at the hospital, but he also paid for his own education. In my mind, he was offering more than what seemed \"reasonable\" to the rest of us. A sacrifice is more than just giving up something. It's something that actually *hurts* that you do anyway because of your belief in a cause. He believed in the cause and was willing to hurt for it.\r\n\r\n## The Work\r\n\r\nWe each went about our duties, as busy as we were. We did our best to attend weekly meetings on our progress, where we'd identify any blockers and discuss solutions. It was *a lot* of work for everyone involved.\r\n\r\nWe had team members over categories like Marketing, Social Media, Hospitality, Sponsorship, and others. I was the Director of Technology, which meant I would be responsible for the hardware lab, coordinating the schedule and tasks for all of our volunteers and oversee any technical mentoring that was needed.\r\n\r\nHowever, when it came time for the event, even though we still each owned our piece of the pie, we all pitched in to help each other and make it happen. This was something I'd read from the great [John Wooden](/woodeinisms/), but that was reinforced in working with this team:\r\n \r\n- **\"It is amazing how much can be accomplished if no one cares who gets the credit.”** - No one was above helping anyone else with any activity. We all did our best to operate as a team rather than just make sure our own responsibilities were covered. We all did everything from setting up chairs to serving snacks to running games to renting hardware to schmoozing sponsors and everything else in between.\r\n\r\n\r\n## The Iteration\r\n\r\nAfter a successful hackathon with very few hiccups, I thought we had earned a well-deserved rest. I was sure there were a few complaints here or there from participants and sponsors alike, but hey, in an event with 180+ participants and ~15 sponsors several employees each, there was bound to be at least _some_ whining. \r\n\r\nIt wasn't that I didn't care, I just thought we had a little bit of time before we needed to worry about it again. My friend felt differently. After the feedback survey came back, he personally spoke with each sponsor, apologizing if necessary for any inconvenience and pledging to make the changes for the next year. I watched as those items of feedback tormented him over the next year, giving each one a great deal of time and attention, making sure no one would be able to raise that complaint again.\r\n\r\nIn other words, he made this idea different by: \r\n\r\n- **Not only accepting, but *seeking* honest feedback** - It wasn't enough to pat himself on the back for a job well done and rest up. He *needed* to address the issues to make the next event  *perfect*. He didn't want to waste any time in pursuit of that goal.\r\n\r\n## The Rest of the Story\r\n\r\nWe did address those issues and prepare for the next year's Hackathon. Our team locked down a title sponsor that gave us over $12,000 on top of many of our sponsorships from the previous year. Because of the event's success, they actually signed a contract to remain the title sponsor over the next 3 years, increasing the donation by 20% each year. \r\n\r\nWe had over 260 participants that created some amazing products, one of which was a robot that used Tensorflow to learn a participants preferences in girls and used a stylus to swipe left or right on his Tinder application.\r\n\r\nMy friend, [Johnny Le](https://johnnyle.me/), went on to win an [award](http://dailyutahchronicle.com/2018/05/21/ideas-are-only-worth-what-you-make-of-them-u-student-starts-utahs-largest-hackathon/) given to one student each year for student leadership that resulted in a $2,000 cash award and a $10,000 donation to the student organization of his choice (guess which organization he gave it to). \r\n\r\nI sincerely hope that none of what I have said comes across as hyperbole or sugar-coated. Like all teams and projects, we had our issues and problems. Even Johnny, as great a guy as he is, makes mistakes. I'm also not saying that these are the only things one needs to do in order to be successful at any given task. I don't pretend to know the secret sauce to success - I'm still trying to find it myself.\r\n\r\nBut [HackTheU](https://hacktheu.com/) didn't end up in the \"Good Idea Graveyard\" because Johnny and our team treated it differently. I had a front row seat to watch some amazing individuals come together, take collective ownership of a good idea and make it happen through initiative, sacrifice, humility and the unglamorous, frustrating, seemingly never-ending **work**.\r\n\r\n*\"You wonder how they do it <br>\r\nAnd you look to see the knack<br>\r\nYou watch the foot in action,<br>\r\nOr the shoulder or the back,<br>\r\nBut when you spot the answer<br>\r\nWhere the higher glamours lurk<br>\r\nYou’ll find in moving higher<br>\r\nUp the laurel covered spire<br>\r\nThat most of it is practice<br>\r\nAnd the rest of it is work\"<br>\r\n -Grantland Rice*"
  },
  "Favorite Woodenisms": {
    "name": "Woodenisms.md",
    "content": "---\r\ntitle: Favorite Woodenisms\r\ndate: 2017-10-12\r\n---\r\n\r\nJohn Wooden was not only one of the greatest coaches of all-time (10 National Championships in 12 seasons at UCLA, 7 of those consecutive) and a great human being, but he had a gift with words. His many one-liners and famous sayings have since become known as \"Woodenisms.\" Here are some of my favorites:\r\n\r\n## Top 10\r\n\r\n1. *\"Be **quick**, but **don't hurry**\"*\r\n\r\n2. *\"Time lost is time lost. It’s gone forever. Some people tell themselves that they will work twice as hard tomorrow to make up for what they did not do today. People should always do their best. If they work twice as hard tomorrow, then they should have also worked twice as hard today. That would have been their best.\"*\r\n\r\n3. *\"Do not permit what you **cannot** do interfere with what you **can** do.\"*\r\n\r\n4. *\"If I am through learning, I am through.\"*\r\n\r\n5. *\"It is what you learn after you know it all that counts.\"*\r\n\r\n6. *\"Tell the truth. That way you don’t have to remember a story.\"*\r\n\r\n7. *\"Being average means you are as close to the bottom as you are to the top.\"*\r\n\r\n8. *\"Don’t measure yourself by what you’ve accomplished, but rather by what you should have accomplished with your abilities.\"*\r\n\r\n9. *\"If you’re not making mistakes, then you’re not doing anything. I’m positive that a doer makes mistakes.\"*\r\n\r\n10. *\"You can’t live a perfect day without doing something for someone who will never be able to repay you.\"*\r\n\r\n## Honorable Mentions\r\n- *\"If you keep too busy learning the tricks of the trade, you may never learn the trade.\"*\r\n\r\n- *\"Let’s face it, we’re all imperfect and we’re going to fall short on occasion. But we must learn from failure and that will enable us to avoid repeating our mistakes. Through adversity, we learn, grow stronger, and become better people.\"*\r\n\r\n- *\"Happiness begins where selfishness ends.\"*\r\n\r\n- *\"Never make excuses. Your friends don’t need them and your foes won’t believe them.\"*\r\n\r\n- *\"You cannot live a perfect day without doing something for another without thought of something in return.\"*\r\n\r\n- *\"We almost have to force or drive ourselves to work hard if we are to reach our potential. If we don’t enjoy what we do, we won’t be able to push as hard as we need to push for as long as we need to push to achieve our best. However, if we enjoy what we do and if we’re enthusiastic about it, we’ll do it better and come closer to becoming the best we can be.\"*\r\n\r\n- *\"Time spent getting even would be better spent getting ahead.\"*\r\n\r\n- *\"Have character; don't be one.\"*\r\n\r\n- *\"The worst thing about new books is that they keep us from reading the old ones.\"*\r\n\r\n- *\"Never mistake activity for achievement.\"*"
  }
}