{"microsoft2016":{"content":"\r\nIn 2016, I had the opportunity of working with the WDG GS Data Insights team at Microsoft. While there, I was given the task of automating the process of taking action on international customer feedback. Because Windows 10 gets such a high volume of feedback from its users, a lot of valuable information sits idly in a database without anyone being able to act on it. Of course, there is always a lot of junk to sift through and LOTS of duplicated pieces of feedback, which made the challenge of automating the process even more interesting.\r\n\r\nI was privileged to work with teams and individuals across Microsoft, many of whom were quite a few pay grades ahead of us lowly interns. One of my absolute favorite parts of my internship was the aspect of collaboration. As my all-time hero once said, \"It's amazing how much can be accomplished when no one cares who gets the credit.\" (John Wooden) While I understand and agree that everyone deserves credit for their work and accolades for a job well-done, I also feel that there is something to be said for those synergistic teams that are able to feed off of one another and do something great because they are more focused on the thrill of the project than their own career advancement.\r\n\r\nI was grateful for my Database Systems course I had taken the previous semester, because I was able to help optimize the database being used. Previously, some of the queries took over a minute (sometimes more) to process. After some of our optimizations, those queries were running in 2 seconds or less.\r\n\r\nIn order to identify actionable feedback and filter out those that had nothing , I worked with a team that has spent the last 2.5 years developing an internal text analytics engine that could help do just that. I met with their team lead on an almost-weekly basis to discuss needs of the project and even help them debug their solution. It was a great partnership and I was grateful for all of their help.\r\n\r\nI also worked with several web technologies, as bugs and Work Items are housed in Visual Studio Online. In order to pass actionable feedback onto developers, I needed a Restful Web API that I could call to \"promote\" such a bug. Thankfully, there was another team of very helpful individuals that managed that API, and that ended up being the easiest part of the project.\r\n\r\nEven after launching our first batch of auto-promoted bugs, the system was not perfect. There were still a few pieces of feedback that probably should not have been promoted, but to give you some perspective, our first batch was only 131 promoted bugs out of 10M+ pieces of feedback sitting in the database. The filtering was not perfect, but it was a start.\r\n\r\nThe rest of the summer was spent trying to refine the process. I worked with teams of native-language speakers to identify the original translation of each feedback to determine the meaning. One of the great eye-openers during this process was the discovery of how difficult machine translation really is. It's an incredibly fascinating problem, but one that seems to have no perfect solution... yet.\r\n\r\nI've accepted an offer to return to the same team for another internship next summer, where I'm told I might be working on helping to improve machine translation. I'm still not sure in what capacity that will be, but I'm just excited to be a part of it.\r\n","data":{"title":"Microsoft - Summer 2016","date":"2016-9-2","path":"microsoft2016"},"isEmpty":false,"excerpt":""},"nbaclustering":{"content":"Player positions in the NBA have become a rather fluid concept. Teams like the Warriors with their \"Lineup of Death\" have shaken the traditional mindset of the basketball world. We wanted to be able to build out a clustering model that used a player's statistics to identify the player's \"true position.\" When we say \"true position,\" we mean the position the player plays most alike. While LeBron James could be listed at just about any position on the floor, we wanted to know what his stats told us. By creating an unsupervised clustering model, players would be grouped together with other players of a similar statistical model.\r\n\r\n## Introduction\r\n\r\nOur Data Mining project was based on looking for statistical groupings in the National Basketball Association that define the different positions in the modern game of basketball. In basketball, often a given position becomes an argument for what will and won’t work on a roster, when it’s really much more complicated than that. We want to define the numbers behind what a guard, forward, wing or center is, as well as look for outliers, such as forwards performing statistically equivalent to guards.\r\nThe key idea to our project was that there is more to a player than his labeled position. As the NBA has changed in the modern game, there has been a tendency to ‘play small’ as popularized by the Golden State Warriors infamous ‘Lineup of Death’. Examples like these have shown that players longtime slotted into a single position are actually more flexible, and possibly more effective, when placed somewhere completely new. Our goal was to use clustering methodology to look for what defines each of the four positions and search for specific groups of players, as well as outliers, in order to view the game differently. Our graphs have been created using Power BI, an interactive data visualization tool, and we strongly recommend opening the dashboard side by side while reading this paper. It can be found at [this link](https://app.powerbi.com/view?r=eyJrIjoiODgzZjhiMmQtYmU5My00NzM4LTk1MjUtNWVhYWUzM2RiYzhlIiwidCI6Ijg0YzMxY2EwLWFjM2ItNGVhZS1hZDExLTUxOWQ4MDIzM2U2ZiIsImMiOjZ9).\r\n\r\n## Data Wrangling and Cleaning\r\n\r\nFor our project, we used individual statistics of players from the 2010 - 2016 seasons in the NBA, which we obtained from [Pro Basketball API](https://probasketballapi.com/). The data didn’t turn out to be perfect and required several rounds of cleaning and refining in order to produce something worth using. To start, there were several non-basketball athletes in the data set, many players were minimum impact competitors who hardly played and didn’t last very long in the NBA, and some categories, like position, were labeled in an extremely haphazard manner. For example, a player could easily be labeled as a Guard, Point Guard, Shooting Guard, Point Guard/Shooting Guard or Shooting Guard/Point Guard with no distinction as to why any particular choice was made. In order to give a wide range of options, we ran our simulations over statistics gathered from each season, as well as an averaged statistical output from the entire 2010 - 2016 data set.\r\n\r\nIn cleaning our data, we eliminated all non-basketball players, required that a player has played at least 20 games and averaged at least 10 minutes played per game. To normalize the position labels and make up for a lack of distinction between some positions, we organized the athletes into four basic positions. “Guard” consists of players labeled Guard, Point Guard or capable of playing Point Guard or Shooting Guard. “Wing” consists of Shooting Guards (only 3 players in the whole dataset labeled as such), hybrid Guard/Forwards and Small Forwards. “Forward” consists of hybrid Small and Power Forwards and pure Power Forwards. And “Center” is our big man group, consisting of hybrid Power Forward/Centers and Centers. While originally, we only had three positions defined, looking at the numbers in the many categories provided by our data source, we felt these four categories most naturally used the distribution to create a good foundation for our analysis and represented the current state of NBA tactics. One of the difficulties in identifying effective clustering measures was the skew in number of players for each position. This is shown in the already-large and increasing number of guards, as depicted below.\r\n\r\n![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/nba-1.png?raw=true)\r\n\r\nThis increase of smaller players seems to agree with the rest of our analysis, as the league is trending towards players who can score from long range as opposed to the traditional, “inside-out” philosophy, but it adds to the challenge of finding effective clustering measures.\r\n\r\n## Initial Analysis\r\n\r\nWe began our analysis by doing simple comparisons among the four positions we had identified. We compared the averages of the box score statistics, the advanced statistics and some of the shot chart statistics to look for simple ways in which the positions differentiated themselves.\r\n\r\n![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/nba-2.png?raw=true)\r\n\r\n![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/nba-3.png?raw=true)\r\n\r\n![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/nba-4.png?raw=true)\r\n\r\n## Clustering\r\n\r\nWe began with clustering our dataset using both hierarchical clustering with single-link distance metrics and assignment-based clustering using k-means++ and Lloyd’s algorithm. We originally used Gonzalez’s as well but found it less effective and switched our comparisons to single-link and k-means++. For both algorithms, we clustered the data from k = 3 to k = 8, using every combination of 7 statistical feature sets for each player: box score, advanced statistics, shot zone, shot range, shot area, action type and shot type. We ran assignment-based clustering for larger values of k, but with the amount of time required to run single-link hierarchical clustering, we limited our comparison from k = 3 to k = 8. Even with the limited scope, this resulted in almost 10,000 different clusterings with no simple way to identify which were better suited for our purposes. In order to find which clusterings best represented our chosen positions, we began searching for “polarity” among the results. We define “polarity” for a group of clusters as the average percentage of the dominant position for each cluster. Ideally, we would want a group of clusters to have a polarity of 100%, which would mean each cluster would consist entirely of one position.\r\n\r\n## Results\r\n\r\nThe first thing we found is that hierarchical clustering with single-link did not perform as well as we thought. We had anticipated that single-link would do well in linking the most statistically similar players one at a time and that this would lead to a more linear clustering of players. What it actually did, in most cases, was produce (K - 1) singleton clusters and 1 large cluster of the rest of the players. This lead to it getting great scores on our polarity tests, because a cluster consists of only 1 or 2 players, it’s pretty easy to get a cluster of 100% the same position. The variation in cluster size is shown in the graph “Cluster Size Standard Deviation.” While not especially valuable for clustering, it was interesting to see the algorithm identify the game’s “superstars” (Russell Westbrook, LeBron James, Kevin Durant, etc.). We then decided to programmatically prioritize cluster sets that had larger chunks of one position in each collection and focus solely on k-means++ assignment-based clustering for our results.\r\n\r\n![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/nba-5.png?raw=true)\r\n\r\nIn the end, our polarity methods determined that the best clustering result was using Lloyd’s algorithm with k-means++, clustering on box score, advanced statistics, shot range (Less than 8 ft., 8-16 ft., 16-24 ft., 24 ft.+), action type (pull-up jumper, alley-oop dunk, etc.) and shot type (2 pt. vs. 3 pt.) for the 2013 season data set where k = 7.\r\n\r\n![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/nba-6.png?raw=true)\r\n\r\nIn figure 5, you can see the basic results of our determined best clustering, organized by position and each cluster’s size. We call cluster 1 the “Attack the Rim” cluster. It consists of high volume inside shooters like Derrick Rose, Kobe Bryant, Brook Lopez and JaVale McGee. It’s interesting to see how this clustering put players in very different positions into the same grouping. Cluster 2 is our “True Point Guards” (traditional, pass-first) collection, with Rajon Rondo, Jrue Holiday, Steve Nash and Eric Bledsoe leading the way. Cluster 4 is referred to as our “Spot-up Shooters” cluster, consisting of high volume outside shooters like Jimmer Fredette, Brandon Rush, CJ McCollum and Jason Terry. Players who are known more for their ability to shoot from the floor, and are most likely subpar defenders. Cluster 7, which we call the “6th Man Cluster”, is another intriguing look. It is full of guards known for high scoring and utility in limited minutes. Matthew Dellavedova, J.J. Barea, Jeremy Lin, Patrick Beverley, Lou Williams, Jerryd Bayless, Shelvin Mack, Iman Shumpert and even Andre Miller are all sorted here.\r\n\r\nWhile these little itemizations are fun, overall, we learned a great deal from this project. The first thing we learned was that more data is not inherently good thing. The more parameters you input, the more confounding and confused your results can become. As your results become harder to visualize, it’s difficult to tell if your results actually mean anything. Clustering is also a difficult problem, and the methodology you decide on at the beginning heavily affects your results. In our quest to determine positional outliers, we also had tremendous success. One example is our “6th Man Cluster”. While being primarily guards, an outlier is the inclusion of Andre Iguodala. Though this is based on the 2013 data set, it feels reminiscent of Iguodala’s run as a key playmaker in Golden State’s aforementioned ‘Lineup of Death’. His ability to play a role far from his position title led to his naming as Finals MVP in Golden State’s championship. Looking to the future, similar clusterings on the 2016 data set have us extremely interested in the futures of Sam Dekker, Kelly Oubre Jr. and Myles Turner. It becomes even more difficult to cluster over a career when taking into consideration the evolution of each player’s style of play. One of the most well-known examples of this was Michael Jordan’s shift from the high-flying dunk virtuoso that he was when he entered the league to the clutch scorer from mid-to-long range that he became near the end of his career. We don’t think the NBA has ever been as simple as slotting 5 players into position on the floor. And it’s only going to get more interesting.\r\n\r\n## Future Work\r\n\r\nIn order to narrow the scope of this project, we chose to cluster based on groups of statistics (box score, advanced, shot type, etc.) rather than individual statistics themselves. This is partly for our own sanity in trying to keep track of 123 different statistical measures for each player over the span of 6 NBA seasons, but mostly because of the combinatorial nightmare that would arise when trying to find effective combinations of statistics for high accuracy in clustering players based on position. Given the time and resources, we would like to run all possible combinations of those stats, or at least a reasonable amount of those combinations, to see if we can fine-tune our view about which statistics really are indicative of position, how those positions change and evolve over time and how the game is influenced by this position fluidity.\r\n","data":{"title":"NBA Position Clustering","date":"2017-4-8","path":"nbaclustering"},"isEmpty":false,"excerpt":""},"woodenisms":{"content":"\r\nJohn Wooden was not only one of the greatest coaches of all-time (10 National Championships in 12 seasons at UCLA, 7 of those consecutive) and a great human being, but he had a gift with words. His many one-liners and famous sayings have since become known as \"Woodenisms.\" Here are some of my favorites:\r\n\r\n## Top 10\r\n\r\n1. *\"Be **quick**, but **don't hurry**\"*\r\n\r\n2. *\"Time lost is time lost. It’s gone forever. Some people tell themselves that they will work twice as hard tomorrow to make up for what they did not do today. People should always do their best. If they work twice as hard tomorrow, then they should have also worked twice as hard today. That would have been their best.\"*\r\n\r\n3. *\"Do not permit what you **cannot** do interfere with what you **can** do.\"*\r\n\r\n4. *\"If I am through learning, I am through.\"*\r\n\r\n5. *\"It is what you learn after you know it all that counts.\"*\r\n\r\n6. *\"Tell the truth. That way you don’t have to remember a story.\"*\r\n\r\n7. *\"Being average means you are as close to the bottom as you are to the top.\"*\r\n\r\n8. *\"Don’t measure yourself by what you’ve accomplished, but rather by what you should have accomplished with your abilities.\"*\r\n\r\n9. *\"If you’re not making mistakes, then you’re not doing anything. I’m positive that a doer makes mistakes.\"*\r\n\r\n10. *\"You can’t live a perfect day without doing something for someone who will never be able to repay you.\"*\r\n\r\n## Honorable Mentions\r\n\r\n- *\"If you keep too busy learning the tricks of the trade, you may never learn the trade.\"*\r\n\r\n- *\"Let’s face it, we’re all imperfect and we’re going to fall short on occasion. But we must learn from failure and that will enable us to avoid repeating our mistakes. Through adversity, we learn, grow stronger, and become better people.\"*\r\n\r\n- *\"Happiness begins where selfishness ends.\"*\r\n\r\n- *\"Never make excuses. Your friends don’t need them and your foes won’t believe them.\"*\r\n\r\n- *\"You cannot live a perfect day without doing something for another without thought of something in return.\"*\r\n\r\n- *\"We almost have to force or drive ourselves to work hard if we are to reach our potential. If we don’t enjoy what we do, we won’t be able to push as hard as we need to push for as long as we need to push to achieve our best. However, if we enjoy what we do and if we’re enthusiastic about it, we’ll do it better and come closer to becoming the best we can be.\"*\r\n\r\n- *\"Time spent getting even would be better spent getting ahead.\"*\r\n\r\n- *\"Have character; don't be one.\"*\r\n\r\n- *\"The worst thing about new books is that they keep us from reading the old ones.\"*\r\n\r\n- *\"Never mistake activity for achievement.\"*\r\n","data":{"title":"Favorite Woodenisms","date":"2017-10-12T00:00:00.000Z","path":"woodenisms"},"isEmpty":false,"excerpt":""},"joiningmicrosoft":{"content":"\r\nI've had a few friends ask me what my journey to Microsoft was like and why I chose to work here. Microsoft, like the Yankees and black licorice, is one of those \"love it or hate it\" kind of things (I fall emphatically into the latter camp for both of those other two). Everyone has reasons or experiences that make them feel one way or the other. As for myself, I've really enjoyed working at Microsoft, so I thought I'd document a little bit of my journey and why I ended up where I did.\r\n\r\n## The Interview\r\n\r\nI first interviewed with Microsoft in 2015 for a summer internship. When they called me and asked me to fly out for a round of final interviews in Redmond, my wife and I saw it as a free trip to Seattle. In my head, I was nowhere near qualified to work at a place like that and had all but written myself off from the start. The [Imposter Syndrome](https://en.wikipedia.org/wiki/Impostor_syndrome) was as real as ever. But I had promised my wife earlier that year that I would take us some place out of Utah that summer for an internship of some kind, so I really did want it to work out.\r\n<!-- \r\n![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/Microsoft/sign.jpg?raw=true) -->\r\n\r\nI didn't feel great about my interviews - a couple of them felt downright terrible. But I did try hard to explain my thought process and walk my interviewers through my solutions to the problems they presented.\r\n\r\nAfter our brains had become sufficiently scrambled through the 4-hour interview process, the recruiters took us to lunch at the Commons. When we came back from lunch, they handed out Microsoft hoodies and swag (pretty much a participation trophy for interviewing, but **score** nonetheless). I was just about to head out the door to go back to the hotel, intent on enjoying the rest of the weekend in Seattle with my sweet wife, when one of the recruiters pulled me aside.\r\n\r\nWe went into a nearby conference room with one of the other recruiters, where they explained that they had an offer on the table for me. Shock doesn't begin to describe what I was feeling. It was cool to see that they were genuinely excited for me. I think they were even more excited for me to tell my wife.\r\n\r\nOn principle, I wouldn't officially accept anything until I had talked to Kate first, so I told them I would send them an email later that day. I called Kate as soon as I left the building and could barely contain my excitement as I tried to explain what just happened, not really knowing the answer myself. We spent the night in downtown Seattle, fully able to relax and imagine what our summer would be like in this new place.\r\n\r\n<!-- ![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/Microsoft/seattle.jpg?raw=true) -->\r\n\r\n## A New Intern\r\n\r\nThe day after I took my last final in May of 2016, we packed up our Highlander with everything we'd need for the next 3 months and made the 12-hour drive to our summer home. Microsoft put us up in an apartment in Redmond, which was close enough to one of the buildings that I could schedule a shuttle to pick me up and take me to the office. I became friends with many of the shuttle drivers I met that summer and remain very close friends with a few of them to this day. I've been to dinner with them, attended funerals of family members, and even stayed in one of their houses while I was looking for a place to stay for my family. Some of the finest people I've ever had the chance to meet.\r\n\r\nI spent that first summer in building 109 of Microsoft's campus, working with the WDG Global Services Localization Data Insights team (kind of a mouthful). My project was to automate the process by which our team identified meaningful feedback, particularly when it came to localization issues in Windows. I was able to work with a few teams across Microsoft to create a system that utilized an internal big data platform and natural language processing/machine learning tools to process and identify feedback most likely to be actionable in order to pass it along to developers.\r\n\r\n<!-- ![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/Microsoft/project.jpg?raw=true) -->\r\n\r\nIt solved a critical business need for the team, as they had previously been hiring sub-contractors to _read each piece of feedback, one by one_ and decide which ones were actionable. That may work for a smaller system, but for something like Windows, that's just not scalable. The project was a success, I learned a ton and had a blast doing it. For more detail on this project, check out my [blog post](/Microsoft-Summer2016/) written right after finishing for the summer. Of course, I enjoyed the many intern events and parties held for us... A private Ellie Goulding concert at the Space Needle where they hand out new Surface Books at the end wasn't anything to sneeze at... But the highlight for me was the learning and growing I was able to do, being surrounded by an amazing group of talented individuals that didn't mind taking the time to teach and mentor an intern.\r\n\r\n<!-- ![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/Microsoft/team.jpg?raw=true) -->\r\n\r\nI accepted an offer to return to the same team the following summer. As these things go, there was a massive re-organization within the team, my manager left Microsoft to pursue a personal dream of civic engagement as the City of Seattle's new Open Data Program Manager, and I would be reporting directly to my previous skip-manager. Although I was very sad to hear my manager would be leaving, I was happy to still be working under someone I knew and respected a great deal.\r\n\r\n## Return of the Intern\r\n\r\nOur journey back to Redmond after a long school year was pretty much the same, aside from one major detail - my wife was 6 months pregnant. She was due on August 10th, just 13 days after I was scheduled to finish my internship. Microsoft was _extremely_ accommodating with us. They put us in an apartment that was literally a 6-minute bike ride from building 109. They told me that if anything came up, I should feel free to take time to be with her and not to worry about work. My recruiters even got us a bag of gifts for the baby from the Microsoft store. We really felt that they had our interests at heart and cared about our little family.\r\n\r\n<!-- ![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/Microsoft/baby.jpg?raw=true) -->\r\n\r\nMy project during that second summer was very broad, more of a question to answer with no real guidance given on the implementation. I was free to take the project in whatever direction I saw fit. The question was \"How do we identify influential communities of Windows users/devices so that we can weight their feedback more heavily?\" These communities went much deeper than just \"gamers, business users, mobile users, etc.\" We already knew that for most devices. I wanted to find a way to use Windows telemetry to cluster devices together that actually *behaved* in a similar way, so that we could amplify the voice of Windows Insiders (users that receive Windows versions before they are released to the public) that more accurately represented that population.\r\n\r\nAt a 30,000 foot level, my approach was fairly straight forward: run k-means clustering on Windows devices within a locale (primary language used on device) and assign each device a score proportional to the size of the cluster and inversely proportional the device's distance from the centroid (higher score = big cluster and close to center). The problem became finding ways to run this efficiently on petabytes of telemetry data and setting it up to run in an automated workflow. The systems we used had a timeout of 2 hours when running a script, so in order to give it time to finish, I was forced to break it up into smaller chunks of data and run many smaller scripts in parallel.\r\n\r\nThe project went well, and laid a foundation for future work in the area. But as with any probabilistic problem (especially when dealing with unsupervised learning), it's difficult to know when you've found the right approach. Testing your solution can be just as hard as developing it in the first place. When it came down to it, 12 weeks just wasn't a lot of time to understand the problem, map out a solution, implement it by myself and verify the results. And when I say \"by myself,\" that's not to say I didn't receive a lot of help throughout the process. I just mean that no one else was _directly_ working on the project with me. I'm confident that given a few more months, we would have come up with a solid approach to answer this question.\r\n\r\n## The Decision\r\n\r\nAt the end of the summer, I had some difficult decisions to make - whether or not to stay at Microsoft and, if I did stay, whether or not to stay with my current team. I really had enjoyed working with these people for the past two summers. I had learned a lot and was sure there was more to learn from them. But I also felt like broadening my horizons and looking at what other teams/companies had to offer. Two of the main things I was looking for were opportunities to challenge myself and grow, as well as a family-friendly atmosphere.\r\n\r\nThroughout the summer, I had been trying to follow the advice of mentors to keep my options open, so I interviewed with several different companies and had informationals with several teams across Microsoft. In that process, I discovered the Partner Catalyst Team, whose charter was basically to code with Microsoft partners on whatever they were building, which often times included contributing to open-source projects and traveling around the world. I met with a couple of the managers from the team, and even jumped on a Hackathon project with one of them as a little test run of what it would be like to work with them. I had a *great* time and learned a lot in the 3 days we worked together.\r\n\r\nWe went home for the summer. I was still talking to and interviewing with several different companies around the West, including leaving my poor wife while she was 8.9 months pregnant to fly to Silicon Valley. After weighing a few options, thinking about what was best for our family and where I could grow the most, I chose to stay at Microsoft, but switch to this new team. Both my wife and I thought this was the right call and we were ecstatic.\r\n\r\nI went to school and finished my last semester, graduating in December of 2017 and returning to Microsoft on January 8th of 2018. The team had been re-organized and renamed as Commercial Software Engineering (CSE), and I'd be specifically working with the Digital Win Room team within that organization. I spent a week with the team, and then took 2 of the 3 available months of paternal leave, which I was able to use at any time before our new son Jack's birthday in August. I couldn't believe how understanding they were and that the team was happy to let me take that time to get the family moved and spend time together before really starting at work.\r\n\r\nI've been officially back for just about 3 months now, and I have had a blast with some really cool projects and fun adventures. I'll do my best to keep the blog updated on the happenings here.\r\n\r\nSo, there you have it. I joined Microsoft because I felt like it would be a place where I could grow as a Software Engineer and, even more importantly, as a husband and father. I stay because those things are still true.\r\n","data":{"title":"Joining Microsoft","date":"2018-6-1","path":"joiningmicrosoft"},"isEmpty":false,"excerpt":""},"thedifference":{"content":"\r\nWe've all been there. Talking with old friends or new acquaintances about your career as a software engineer, and those magical words pop into the conversation: \"_Bro... I have an idea for this app..._\" Much to the surprise and chagrin of many aspiring Zuckerbergs, success comes from a heck of a lot more than just a good idea.\r\n\r\nMy purpose here is not to disparage any idea. I think some of the best ideas in the world are those that sound insane from the start. My purpose is to reflect on one of my own experiences and use it to identify some of the things that separate the successful ideas from... well... the others.\r\n\r\n![alt text](/images/kramer.gif)\r\n\r\nThis experience I'm talking about was a time that I was able to witness the end-to-end process of an idea becoming a success. It started similarly to the other experiences I referenced in the beginning of this post - a friend came to me with an idea, and an ambitious one at that.\r\n\r\n_(cue [flashback music from \"Arthur\"](https://www.youtube.com/watch?v=KSm377MSv7Y))_\r\n\r\n## The Idea\r\n\r\nIt was April of 2016. I was just about to finish one of the most difficult semesters I'd had to date. I was trying to understand Turing machines, Database relational algebra, and every sorting algorithm ever made since the caveman stacked the biggest rocks at the bottom. For those of you who haven't experienced this, just imagine you're drowning... You cry out for help, hoping someone is close enough hear you... But the only response you get is from your terminal: `Segmentation fault`.\r\n\r\nIn the heat of the confusion, rage and tears, this friend approached me with an idea to create the biggest hackathon in the state of Utah. He wanted it to happen in the upcoming semester (in 5 months) and that he wanted me to help him do it.\r\n\r\nAt the time, I thought, _\"**How** could we ever do that? **Where** would we even find the time? **Why** put more on our plate than we already have?\"_\r\n\r\nIt's safe to say I had my doubts. But after thinking about it for a few days, I thought it sounded kind of fun and that I'd join him. He recruited a few of our other classmates that were either crazy enough to say \"yes\" or too scared to tell him \"no.\" We had ourselves a team.\r\n\r\n## The Team\r\n\r\nOur first official meeting was a few weeks later, and was actually a video conference, as several of us were working at internships in different states. We jumped on the call and realized that none of us really knew any of the others, except for this friend that had pulled us into this. We weren't anti-social, but we each had our own spheres and didn't often venture outside them.\r\n\r\nI thought to myself, \"This is quite possibly the most random possible sampling of students in the University of Utah Computer Science program...\" Looking back, I realize that these were some of the first indications of differences between this idea and many of the others I'd heard:\r\n\r\n- **Assemble a *diverse* team** - Seriously, we could have been a poster for a University marketing campaign. We had just about every demographic covered. But diversity became much more than a box to check. A team with different backgrounds, perspectives, connections and opinions would become crucial to the success of the hackathon.\r\n- **Find the *right* people** - Rather than just pick his friends, he went out and picked people that would be right for each job and helped them catch the vision. I'm not saying the people on the team weren't his friends, but I think it's easy to fall into the trap of just defaulting to your circle of closest friends, even if they're not right for the job.\r\n\r\n## The Sacrifice\r\n\r\nI'll never forget the day we went to ASUU (Associated Students of the University of Utah), our school's student government, to ask for their financial sponsorship of our event. We came on a day where other clubs and student groups were being grilled by the student-legislators over requests in the $50-$100 range. We were coming in asking for $3,000.\r\n\r\nBut not only did we believe this event would be fun and impactful for each of the participants personally, we strongly felt it would benefit the University and the community in the long run.\r\n\r\nBig hackathons were starting to become one of the ways students from other schools in and out of the state were exposed to universities, and many of them would eventually plan on going to graduate school. We felt that if we could just give these students a chance to see what it's like to be at the University of Utah, more would consider the U for future educational opportunities.\r\n\r\nThese hackathons are also *major* opportunities for companies to recruit potential candidates (hence the corporate sponsors that shelled out $$$ for a booth at the event and their logo on our materials and website). If we could host a large event where students from around the state and country could get face time with local companies, it was possible that many of those participants would receive job offers, work in the area, and boost the local economy.\r\n\r\nSo, yes, $3000 from the University seemed like a lot up front, but we felt like the investment would pay for itself many times over.\r\n\r\nWhen we got up to pitch the idea to this group of our peers, many of them caught the vision, but there were also some that just couldn't get over the amount of money we were asking for.\r\n\r\nOne of them posed the question, *\"What will you do if you don't get the money?\"*\r\n\r\nMy friend answered without hesitation, *\"It will come out of my own pocket. I believe in this cause and it's something I'm willing to pay for if we don't get the funding.\"* I was as surprised as each of them. Which brings me to the next difference:\r\n\r\n- **Be willing to make *real* sacrifices** - It's not like he was made of money, either. He worked long hours at the hospital, but he also paid for his own education. In my mind, he was offering more than what seemed \"reasonable\" to the rest of us. A sacrifice is more than just giving up something. It's something that actually *hurts* that you do anyway because of your belief in a cause. He believed in the cause and was willing to hurt for it.\r\n\r\n## The Work\r\n\r\nWe each went about our duties, as busy as we were. We did our best to attend weekly meetings on our progress, where we'd identify any blockers and discuss solutions. It was *a lot* of work for everyone involved.\r\n\r\nWe had team members over categories like Marketing, Social Media, Hospitality, Sponsorship, and others. I was the Director of Technology, which meant I would be responsible for the hardware lab, coordinating the schedule and tasks for all of our volunteers and oversee any technical mentoring that was needed.\r\n\r\nHowever, when it came time for the event, even though we still each owned our piece of the pie, we all pitched in to help each other and make it happen. This was something I'd read from the great [John Wooden](/woodeinisms/), but that was reinforced in working with this team:\r\n\r\n- **\"It is amazing how much can be accomplished if no one cares who gets the credit.”** - No one was above helping anyone else with any activity. We all did our best to operate as a team rather than just make sure our own responsibilities were covered. We all did everything from setting up chairs to serving snacks to running games to renting hardware to schmoozing sponsors and everything else in between.\r\n\r\n## The Iteration\r\n\r\nAfter a successful hackathon with very few hiccups, I thought we had earned a well-deserved rest. I was sure there were a few complaints here or there from participants and sponsors alike, but hey, in an event with 180+ participants and ~15 sponsors several employees each, there was bound to be at least _some_ whining.\r\n\r\nIt wasn't that I didn't care, I just thought we had a little bit of time before we needed to worry about it again. My friend felt differently. After the feedback survey came back, he personally spoke with each sponsor, apologizing if necessary for any inconvenience and pledging to make the changes for the next year. I watched as those items of feedback tormented him over the next year, giving each one a great deal of time and attention, making sure no one would be able to raise that complaint again.\r\n\r\nIn other words, he made this idea different by:\r\n\r\n- **Not only accepting, but *seeking* honest feedback** - It wasn't enough to pat himself on the back for a job well done and rest up. He *needed* to address the issues to make the next event  *perfect*. He didn't want to waste any time in pursuit of that goal.\r\n\r\n## The Rest of the Story\r\n\r\nWe did address those issues and prepare for the next year's Hackathon. Our team locked down a title sponsor that gave us over $12,000 on top of many of our sponsorships from the previous year. Because of the event's success, they actually signed a contract to remain the title sponsor over the next 3 years, increasing the donation by 20% each year.\r\n\r\nWe had over 260 participants that created some amazing products, one of which was a robot that used Tensorflow to learn a participants preferences in girls and used a stylus to swipe left or right on his Tinder application.\r\n\r\nMy friend, [Johnny Le](https://johnnyle.me/), went on to win an [award](http://dailyutahchronicle.com/2018/05/21/ideas-are-only-worth-what-you-make-of-them-u-student-starts-utahs-largest-hackathon/) given to one student each year for student leadership that resulted in a $2,000 cash award and a $10,000 donation to the student organization of his choice (guess which organization he gave it to).\r\n\r\nI sincerely hope that none of what I have said comes across as hyperbole or sugar-coated. Like all teams and projects, we had our issues and problems. Even Johnny, as great a guy as he is, makes mistakes. I'm also not saying that these are the only things one needs to do in order to be successful at any given task. I don't pretend to know the secret sauce to success - I'm still trying to find it myself.\r\n\r\nBut [HackTheU](https://hacktheu.com/) didn't end up in the \"Good Idea Graveyard\" because Johnny and our team treated it differently. I had a front row seat to watch some amazing individuals come together, take collective ownership of a good idea and make it happen through initiative, sacrifice, humility and the unglamorous, frustrating, seemingly never-ending **work**.\r\n\r\n*\"You wonder how they do it <br>\r\nAnd you look to see the knack<br>\r\nYou watch the foot in action,<br>\r\nOr the shoulder or the back,<br>\r\nBut when you spot the answer<br>\r\nWhere the higher glamours lurk<br>\r\nYou’ll find in moving higher<br>\r\nUp the laurel covered spire<br>\r\nThat most of it is practice<br>\r\nAnd the rest of it is work\"<br>\r\n -Grantland Rice*\r\n","data":{"title":"The Difference - What Makes an Idea Work","date":"2018-6-15","path":"thedifference"},"isEmpty":false,"excerpt":""},"bucketlist":{"content":"\r\nThis is an ever-growing, ever-changing list of things I would like to accomplish as a software engineer, both in my professional and personal life.\r\n\r\n- [ ] Find an interesting open-source project and submit a PR within 24 hours of discovering it\r\n- [ ] File a patent for software you wrote (at work or otherwise)\r\n- [x] Write a REST API\r\n- [x] Write a serverless function\r\n- [x] Containerize an application\r\n- [x] Make your own website\r\n- [ ] Work pager duty\r\n- [x] Participate in a hackathon\r\n- [x] Travel for work\r\n  - International\r\n    - Barcelona\r\n    - London\r\n    - Paris\r\n    - Buenos Aires\r\n  - Domestic\r\n    - Cleveland (2x)\r\n    - Dallas\r\n    - Portland\r\n    - San Francisco\r\n- [x] Travel to attend a major software conference\r\n- [ ] Travel to speak or present at a major software conference\r\n- [x] Find a senior developer mentor\r\n- [x] Mentor a junior developer\r\n- [x] Submit code to these online package managers\r\n  - [x] PyPI\r\n  - [x] NuGet\r\n  - [x] NPM\r\n- [ ] Have a stranger submit a meaningful PR to an open-source project you created\r\n- [ ] Pull an all-nighter coding on a personal project\r\n- [x] Write a piece of software just for you that you actually use\r\n- [ ] Reading list:\r\n  - [ ] [Clean Code](https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882)\r\n  - [x] [The Night Watch](https://www.usenix.org/system/files/1311_05-08_mickens.pdf)\r\n  - [x] [Cracking the Coding Interview](https://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/0984782850/ref=dp_ob_title_bk)\r\n  - [ ] [Design Patterns: Elements of Reusable Object-Oriented Software](https://www.amazon.com/Design-Patterns-Elements-Reusable-Object-Oriented/dp/0201633612)\r\n  - [ ] [Code: The Hidden Language of Computer Hardware and Software](https://www.amazon.com/Code-Language-Computer-Hardware-Software/dp/0735611319)\r\n  - [ ] [Refactoring: Improving the Design of Existing Code](https://www.amazon.com/Refactoring-Improving-Design-Existing-Code/dp/0201485672)\r\n  - [ ] [The Pragmatic Programmer](https://www.amazon.com/Pragmatic-Programmer-Journeyman-Master/dp/020161622X)\r\n  - [ ] [Code Complete: A Practical Handbook of Software Construction](https://www.amazon.com/Code-Complete-Practical-Handbook-Construction/dp/0735619670/ref=pd_lpo_sbs_14_t_1?_encoding=UTF8&psc=1&refRID=K75WSC0JK6J62XWX4AHR)\r\n  - [x] [Real Programmers Don't Use PASCAL](http://web.mit.edu/humor/Computers/real.programmers)\r\n- [x] Work with a dataset larger than one petabyte\r\n- [x] Write your own ML model using nothing but a math library (numpy or equivalent)\r\n- [x] Throw away code for a project and start from scratch\r\n- [x] Work in an open-space environment\r\n- [x] Work in an office/cubicle environment\r\n- [x] Work for a tech giant\r\n- [ ] Work for a startup with < 10 engineers\r\n- [ ] Work as a manager for a dev team\r\n- [ ] Write your favorite game in any language\r\n- [x] Write a mobile app specifically for one platform\r\n- [ ] Write a cross-platform mobile app\r\n- [ ] Work as a freelancer\r\n- [x] Teach a kid to code\r\n- [x] Teach a class on programming\r\n- [ ] Write and publish a technical book\r\n- [ ] Receive a job offer without an interview\r\n- [ ] Publish a technical tutorial\r\n- [ ] Answer a question on StackOverflow\r\n- [ ] Have an answer upvoted 100+ times on StackOverflow\r\n- [ ] Write a program using strictly Vim or Emacs in the terminal\r\n- [ ] Write a non-trivial program in:\r\n  - [x] C\r\n  - [x] MIPS\r\n  - [ ] Go\r\n  - [x] C++\r\n  - [x] C#\r\n  - [x] Node.js\r\n  - [x] TypeScript\r\n  - [x] Python\r\n  - [x] Java\r\n  - [x] Android\r\n  - [ ] Swift\r\n  - [ ] Rust\r\n  - [ ] Elixir\r\n  - [ ] Scala\r\n- [ ] Write a program in a functional language\r\n- [x] Write a program for a robot\r\n- [ ] Work on software that requires government clearance\r\n- [ ] Infiltrate a large system undetected\r\n- [ ] Place top 5 in a Kaggle competition\r\n- [x] Write a blog about your career\r\n","data":{"title":"My Software Dev Bucket List","date":"2018-8-31","path":"bucketlist"},"isEmpty":false,"excerpt":""},"pycon2019":{"content":"\r\nThis is a summary of 5 of my favorite talks from PyCon 2019. I learned a ton throughout the conference and felt that the learnings needed to be shared. I've tried to summarize as best as I could from the notes that I took. I believe the talks will be available online soon if they are not already. Big thanks to the speakers for all the effort they put in to make their talks so practical and engaging.\r\n\r\n## Black Swans - Keynote from Russell Keith-Magee\r\n  \r\n  This was the first keynote of the conference, and it was **awesome**. Mr. Keith-Magee discussed the [black swan theory](https://en.wikipedia.org/wiki/Black_swan_theory), which, as a very crude summary, are things that seem obvious in hindsight but that no one had thought of previously.\r\n  \r\n  He tied that to the 1983 America's Cup winning sailing team from Perth, Australia, and their use of the [winged keel](https://en.wikipedia.org/wiki/Winged_keel). This innovation helped their boat move with less resistance. Sailboats had been roughly the same for the previous few decades and teams that failed to innovate were left behind. He invited us to challenge our assumptions and to look for \"black swan\" innovations, particularly relating to the open-source and Python communities.\r\n\r\n## Break the cycle: three excellent python tools to automate repetitive tasks - Thea Flowers\r\n\r\n### 1. `tox`\r\n\r\nOne of the most common tools used in Python applications. Used to run tests in multiple environments and even multiple versions of frameworks. For example if you want your app to support multiple versions of Python and multiple versions of Flask, your `.ini` file could look something like (example taken from the `flask-restful` repo):\r\n\r\n```\r\n[tox]\r\nenvlist=\r\n    py{27,34,35,36,37}-flask{0_10,0_12,10}\r\n\r\ndeps =\r\n    flask0_10: flask>=0.10,<0.11\r\n    flask0_12: flask>=0.12,<1.0\r\n    flask10:   flask>=1.0,<1.1\r\n\r\n[testenv]\r\nusedevelop = true\r\ncommands =\r\n    pip install -e .\r\n    nosetests\r\ndeps =\r\n    -r{toxinidir}/tests/requirements.txt\r\n```\r\n\r\nWhen the command `tox` is executed, this would run the test suite **15 times** (cross product of Python environments and Flask versions - `5 x 3 = 15`). As part of that process, it would install the necessary dependencies in virtual environments (according to each version) and run the tests. Pretty cool.\r\n\r\n### 2. `nox`\r\n\r\nPretty cool to listen to a talk from the original `nox` author. `nox` is very similar to `tox`, but rather than using the `.ini` file, its configuration is done in Python itself. The `nox` equivalent to the `tox.ini` file above would be something like:\r\n\r\n```python\r\n@nox.session(python=['2.7', '3.4', '3.5', '3.6', '3.7'])\r\n@nox.parameterize('flask', ['0.10', '0.12', '1.0'])\r\ndef tests(session, flask):\r\n    # Install pytest\r\n    session.install('pytest')\r\n    # Install version of flask\r\n    session.install(f'flask=={flask}')\r\n    # Install everything in requirements-dev.txt\r\n    session.install('-r', 'requirements-dev.txt')\r\n    # Install the current package in editable mode.\r\n    session.install('-e', '.')\r\n    # Run pytest. This uses the pytest executable in the virtualenv.\r\n    session.run('pytest')\r\n```\r\n\r\nAlso a really cool option, which is helpful if you need something slightly more flexible than `nox` or if you'd rather write config-as-code.\r\n\r\n### 3. `invoke`\r\n\r\nInvoke is seen as a more flexible automation tool. For example (straight from `invoke`'s docs):\r\n\r\n```python\r\nfrom invoke import task\r\n\r\n@task\r\ndef clean(c, docs=False, bytecode=False, extra=''):\r\n    patterns = ['build']\r\n    if docs:\r\n        patterns.append('docs/_build')\r\n    if bytecode:\r\n        patterns.append('**/*.pyc')\r\n    if extra:\r\n        patterns.append(extra)\r\n    for pattern in patterns:\r\n        c.run(\"rm -rf {}\".format(pattern))\r\n\r\n@task\r\ndef build(c, docs=False):\r\n    c.run(\"python setup.py build\")\r\n    if docs:\r\n        c.run(\"sphinx-build docs docs/_build\")\r\n```\r\n\r\nwhich is run by calling:\r\n\r\n```bash\r\n$ invoke clean build\r\n```\r\n\r\nThis can be very useful even outside of things like Python testing. Planning on converting some of the scripts I use on my machine to `invoke` commands.\r\n\r\n## Wily Python: Writing simpler and more maintainable Python - Anthony Shaw\r\n  \r\nThis talk was definitely one of my favorites. We had just talked a lot about code complexity when working on [VoTT](https://github.com/microsoft/VoTT), and not many of us knew exactly how that was calculated. Anthony talked about three different ways to measure code complexity and how all of them play a factor in calculating the \"maintainability index\".\r\n\r\nThe first, most crude way of measuring complexity is by **lines of code**. Fewer lines *can* be less complicated, but in a language like Python, you could have a one-liner like this function for the Sieve of Eratosthenes:\r\n\r\n```python\r\ndef sieve_eratosthenes(n):\r\n    return sorted(set(range(2,n+1)).difference(set((p * f) for p in range(2,int(n**0.5) + 2) for f in range(2,(n/p)+1))))\r\n```\r\n\r\nAnother measure is by **cyclomatic complexity**, for which he gave the example of ordering a Big Mac:\r\n\r\n```\r\nCASHIER: What would you like?\r\nME: I'd like a Big Mac please\r\nCASHIER: Make it a meal?\r\nME: Sure\r\nCASHIER: Small, large or super size?\r\nME: Large\r\nCASHIER: What would you like to drink?\r\nME: Coke\r\nCASHIER: Diet or regular?\r\nME: Regular\r\n```\r\n\r\nJust in that interaction, the cyclomatic complexity would be **5**, which is basically *the number of decisions that need to be made*. In Python, things like `if`, `elif` and `try` are things that increase cyclomatic complexity.\r\n\r\nThis is why you might get asked in a code review to \"invert `if` statement to reduce nesting.\" The phrase *\"flat is better than nested\"* is directly from the Zen of Python (discussed more below) and explained in the famous email to the Python mailing list [Why \"flat is better than nested\"?](https://mail.python.org/pipermail/python-list/2010-October/590762.html).\r\n\r\nWhere the code complexity measurement gets more \"mathy\" is when we start talking about Halstead Complexity measures. I won't go too deep into this, but it involves operators, operands, sums of each and much more.\r\n\r\nWhen you combine these three measurements, you can calculate the `maintainability index` as such:\r\n\r\n```\r\nMI = 171 - 5.2 * ln(Halstead Volume) - 0.23 * (Cyclomatic Complexity) - 16.2 * ln(Lines of Code)\r\n```\r\n\r\nThere have been variations of this original formula, which you can read about [here](http://www.projectcodemeter.com/cost_estimation/help/GL_maintainability.htm)\r\n\r\nAfter discussing the theory behind all of this, Mr. Shaw introduced the Python utility he wrote called `wily`, which you can install on pip. `wily` is \"A command-line application for tracking, reporting on complexity of Python tests and applications.\" Definitely planning on using `wily` in my next Python project!\r\n\r\n## The Zen of Python Teams - Adrienne Lowe\r\n  \r\nMany people are familiar with \"The Zen of Python\" as laid out in an email from Tim Peters and described on python.org as \"guiding principles for Python's design into 20 aphorisms, only 19 of which have been written down.\" (meaning the 20th is something for us as a community to fill in for ourselves)\r\n\r\nHere are the 19 aphorisms:\r\n\r\n```\r\nBeautiful is better than ugly.\r\nExplicit is better than implicit.\r\nSimple is better than complex.\r\nComplex is better than complicated.\r\nFlat is better than nested.\r\nSparse is better than dense.\r\nReadability counts.\r\nSpecial cases aren't special enough to break the rules.\r\nAlthough practicality beats purity.\r\nErrors should never pass silently.\r\nUnless explicitly silenced.\r\nIn the face of ambiguity, refuse the temptation to guess.\r\nThere should be one-- and preferably only one --obvious way to do it.\r\nAlthough that way may not be obvious at first unless you're Dutch.\r\nNow is better than never.\r\nAlthough never is often better than *right* now.\r\nIf the implementation is hard to explain, it's a bad idea.\r\nIf the implementation is easy to explain, it may be a good idea.\r\nNamespaces are one honking great idea -- let's do more of those! \r\n```\r\n\r\n(If you didn't know, these are in a Python Easter Egg. Fire up `python` in your terminal and type\r\n\r\n```\r\n>>> import this\r\n```\r\n\r\nto see what I mean.)\r\n\r\nThese sayings are usually applied directly to the code that we write, but Adrienne Lowe discussed how we can take some of these principles and apply them directly to how we work within our teams. Here are a few that she discussed:\r\n\r\n### \"Beautiful is better than ugly\"\r\n\r\nWe can avoid \"acting ugly\" with our teammates. \"Acting ugly\" can come in the form of bitter, cutting code reviews, hoarding information and refusing to collaborate with others.\r\n\r\nShe referenced Westrum's [\"A typology of organisational cultures\"](https://qualitysafety.bmj.com/content/13/suppl_2/ii22), which discusses three different types of cultures in a team:\r\n\r\n#### 1. Pathological\r\n\r\n- Information is a **personal** resource (not to be shared)\r\n- Cooperation is discouraged\r\n- Failure leads to scapegoating\r\n- Accidents lead to blaming\r\n\r\n#### 2. Bureaucratic\r\n\r\n- Responsibilities are narrow\r\n- Alignment of team takes precedent over mission\r\n- Failure leads to seeking justice\r\n- Novelty leads to problems\r\n- Maintain turf\r\n- Insist on being done by the book - their book\r\n- Inter-team dynamics neglected\r\n\r\nThis one reminded me immediately of the old cartoon depicting Microsoft's organizational culture-of-old:\r\n\r\n![alt text](https://dougbelshaw.com/blog/wp-content/uploads/2013/09/organizational_charts.png)\r\n\r\nThankfully, I can say that in my ~2 years working for Microsoft, I have yet to experience that kind of culture. Things have changed :)\r\n\r\n#### 3. Generative (the goal)\r\n\r\n- High cooperation\r\n- Risks are shared\r\n- Failure leads to inquiry\r\n- Information flows freely\r\n- How can we accomplish our goal (\"we\" is expansive and inclusive of all)\r\n\r\n### \"Explicit is better than implicit\"\r\n\r\n- We should *always* have playbooks, documents, resources, onboarding guides and steps to take when confused\r\n- Having these in place and other process documentation makes it easier to include others and speeds up the work\r\n- It is better to keep conversations about code in **main channels** of Slack or whatever messaging service you use as opposed to DMs or other private places. Helps everyone benefit from the knowledge being shared\r\n- Documenting process also improves relationship between teams\r\n- We should **document our people**\r\n  - I enjoy working on...\r\n  - I get excited by...\r\n  - I struggle when...\r\n  - I feel appreciated when...\r\n  - I prefer feedback...\r\n  - Ask me for help with...\r\n- Helps with process of working within teams an can be extremely valuable\r\n\r\n### \"Simple is better than complex\"\r\n\r\n- We build meaningful relationships with small interactions that increase understanding and trust\r\n- Take time to have coffee with colleagues, catch up on weekend, etc.\r\n- **Remote teams** -> Remote Happy Hours - just jump on a video call to chat about lives\r\n- Build trust and familiarity with colleagues\r\n- Like software, we build relationships with small but meaningful actions\r\n\r\n### \"Errors should never pass silently\"\r\n\r\n- If something is wrong with my code, I want to know\r\n- If I do something to hurt someone, I want to know\r\n- We rely on other humans to know that we hurt them\r\n- Feedback is the tool we have to understand our impact on others\r\n- On healthy teams, people should understand what things they need to do to improve\r\n- Be careful about how you respond about mistakes. We all need to be open about mistakes and willing to \"share our trash\" to the point that we're not self-conscious about getting feedback from others.\r\n\r\n### \"In the face of ambiguity, refuse the temptation to guess\"\r\n\r\n- Don't `git blame` and stew about it\r\n- Assume the best and don't guess at motives.\r\n- Ask where they're coming from and try to understand why they did what they did\r\n- Be assertive\r\n- Open issues, comment on PRs\r\n- Challenge directly but care personally\r\n- Don't explain away code... or people\r\n- Especially for managers. Don't guess about how your direct reports are doing. You should know.\r\n\r\n### \"Now is better than never\"\r\n\r\n- Take **some** action to move closer to our goal\r\n- \"Doing and being wrong is a lot better than not doing at all\"\r\n- Everyone benefits from being reminded that they can start where they are\r\n- **Challenge** - Fill in the 20th line of the Zen and share it on social media with `#HereYaGoGuido`\r\n\r\n## Type hinting and `mypy` - Bernat Gabor\r\n\r\n- Why use types in Python? Why not just use Java/C#?\r\n  - Makes code easier to:\r\n    - understand\r\n    - use\r\n    - maintain\r\n    - debug\r\n    - refactor\r\n  - Creates more accurate code suggestions\r\n  - Does lint checks that find bugs with no tests\r\n  - Improve documentation\r\n  - Built-in data validation\r\n  - Performance increase (sometimes)\r\n    - `mypyc` - Compiles c-extension type hinted code (not full syntax support yet), can lead to 4 to 20x performance improvement (due to the avoidance of hashtable lookups)\r\n- You can *gradually* introduce typings into your code (not all or nothing)\r\n- Typing example:\r\n\r\n```python\r\ndef greeting(name: str) -> str:\r\n    s: str = name # You can add type annotations inline\r\n    return s\r\n```\r\n\r\n- Gotchas\r\n  - If you have to maintain both Python 2 & 3, this will be difficult\r\n  - If you have multiple return types, the best way to use typings will be to use the `@overload` decorator and declare the function multiple times\r\n  - Type lookup - looks for type in closest namespace\r\n    - For example, if you have a function named `float` that returns a `float` data type, it will type the return value as the function itself\r\n- Typing packages\r\n  - `mypy` - Reference implementation type checker\r\n  - `pyre` - Facebook\r\n  - `pytype` - Google\r\n  - `pyright` - Microsoft (fun fact - written in TypeScript)\r\n\r\n## Conclusion\r\n\r\nI hope this summary was of value to someone. Thank you again to the speakers and organizers of PyCon 2019.\r\n","data":{"title":"Top 5 (unordered) Learnings from PyCon 2019","date":"2019-5-6","path":"pycon2019"},"isEmpty":false,"excerpt":""},"serverlesspart1":{"content":"\r\n## Overview\r\n\r\n(_See the [original post here](https://serverless.com/blog/serverless-azure-functions-v2)._)\r\n\r\nWith the [recent updates to the `serverless-azure-functions` plugin](https://github.com/serverless/serverless-azure-functions/blob/master/CHANGELOG.md), it is now easier than ever to create, deploy and maintain a real-world REST API running on Azure Functions. This post will walk you through the first few steps of doing that.\r\n\r\nTo see the full end-to-end example used to create this demo, check out [my GitHub repo](https://github.com/tbarlow12/sls-az-func-rest-api). I structured [each commit](https://github.com/tbarlow12/sls-az-func-rest-api/commits/master) to follow the steps described in this post. Any steps named `Step X.X` are steps that involve no code or configuration changes (and thus not tracked by source control), but actions that could/should be taken at that point in the process. This is done to preserve the \"commit-per-step\" structure of the example repo.\r\n\r\nThis post will only cover the basics of creating and deploying a REST API with Azure Functions, which includes [step 1](https://github.com/tbarlow12/sls-az-func-rest-api/commit/6cd5deebf34645f1ebc829d590e0b169e6c23e29) and [step 2](https://github.com/tbarlow12/sls-az-func-rest-api/commit/5ac83c915e7e78ecfe8e30e03c8425d09c1de936) from the example repo. Stay tuned for posts on the additional steps in the future.\r\n\r\nI will make the assumption that you have the Serverless Framework installed globally. If you do not (or have not updated in a while), run:\r\n\r\n```\r\nnpm i serverless -g\r\n```\r\n\r\nAlso, the `serverless` CLI can be referenced by either `serverless` or `sls`. I will use `sls` in this post just because it's shorter, but `serverless` would work just the same.\r\n\r\n## Step 1: Create your local Azure Function project\r\n\r\nLet's begin by creating our Azure Function project with a template from serverless.\r\n\r\n```\r\nsls create -t azure-nodejs -p sls-az-func-rest-api\r\n```\r\n\r\nThe resulting project will be in the directory `sls-az-func-rest-api`. `cd` into that directory and run `npm install`. To make sure you have the latest version of the Azure Functions plugin, run:\r\n\r\n```\r\nnpm install serverless-azure-functions --save\r\n```\r\n\r\nIt’s important to note that the generated `serverless.yml` file will contain a lot of commented lines, which start with `#`. Those are purely for your benefit in exploring features of the Azure Functions plugin, and can be safely removed.\r\n\r\n## Step 2: Add your own handlers\r\n\r\nFor the sake of this demo, we’re going to create a basic wrapper of the GitHub API for [issues](https://developer.github.com/v3/issues/) and [pull requests](https://developer.github.com/v3/pulls/).\r\n\r\nAs you’ve probably already noticed, the `azure-nodejs` [template](https://github.com/serverless/serverless/tree/master/lib/plugins/create/templates/azure-nodejs) comes pre-loaded with two functions: `hello` and `goodbye`. Let’s remove those before we start adding our own code. To do this, remove both the `hello.js` and `goodbye.js` files. Also, remove their configuration definitions from `serverless.yml`.\r\n\r\nRight now your file structure should look something like:\r\n\r\n```\r\nsls-az-func-rest-api\r\n|-- host.json\r\n|-- package.json\r\n|-- README.md\r\n|-- serverless.yml\r\n```\r\n\r\nand your `serverless.yml` should look like (not including any comments):\r\n\r\n```yaml\r\nservice: sls-az-func-rest-api \r\n \r\nprovider:\r\n  name: azure\r\n  region: West US 2\r\n  runtime: nodejs10.x\r\n \r\nplugins:\r\n  - serverless-azure-functions\r\n \r\npackage:\r\n  exclude:\r\n    - local.settings.json\r\n    - .vscode/**\r\n \r\nfunctions:\r\n```\r\n\r\n### Add Code\r\n\r\nLet’s add in our own code. We’ll start by creating the directory `src/handlers`. This, perhaps to your great surprise, will be where our handlers will live. Inside that directory, we will put our two handlers: [issues.js](https://github.com/tbarlow12/sls-az-func-rest-api/blob/master/src/handlers/issues.js) and [pulls.js](https://github.com/tbarlow12/sls-az-func-rest-api/blob/master/src/handlers/pulls.js).\r\n\r\n```javascript\r\n// src/handlers/issues.js\r\n\r\nconst utils = require(\"../utils\");\r\nconst axios = require(\"axios\");\r\n\r\nmodule.exports.handler = async (context, req) => {\r\n  context.log(\"Issue Handler hit\");\r\n\r\n  const owner = utils.getQueryOrBodyParam(req, \"owner\");\r\n  const repo = utils.getQueryOrBodyParam(req, \"repo\");\r\n\r\n  if (owner && repo) {\r\n    const response = await axios({\r\n      url: `https://api.github.com/repos/${owner}/${repo}/issues`,\r\n      method: \"get\"\r\n    });\r\n    context.res = {\r\n      status: 200,\r\n      body: response.data\r\n    };\r\n  } else {\r\n    context.res = {\r\n      status: 400,\r\n      body: \"Please pass the name of an owner and a repo in the request\"\r\n    };\r\n  }\r\n};\r\n```\r\n\r\n```javascript\r\n// src/handlers/pulls.js\r\n\r\nconst utils = require(\"../utils\");\r\nconst axios = require(\"axios\");\r\n\r\nmodule.exports.handler = async (context, req) => {\r\n  context.log(\"Pull Request Handler hit\");\r\n\r\n  const owner = utils.getQueryOrBodyParam(req, \"owner\");\r\n  const repo = utils.getQueryOrBodyParam(req, \"repo\");\r\n  \r\n  if (owner && repo) {\r\n    const response = await axios({\r\n      url: `https://api.github.com/repos/${owner}/${repo}/pulls`,\r\n      method: \"get\"\r\n    });\r\n    context.res = {\r\n      status: 200,\r\n      body: response.data\r\n    };\r\n  } else {\r\n    context.res = {\r\n      status: 400,\r\n      body: \"Please pass the name of an owner and a repo in the request\"\r\n    };\r\n  }\r\n};\r\n```\r\n\r\nJust for fun, we’ll also add a [utils.js](https://github.com/tbarlow12/sls-az-func-rest-api/blob/master/src/utils.js) file for shared utility functions across handlers, and we’ll put that just inside the `src` directory.\r\n\r\n```javascript\r\n// src/utils.js\r\n\r\n/** Gets the param from either the query string\r\n * or body of request\r\n */\r\nmodule.exports.getQueryOrBodyParam = (req, param) => {\r\n  const { query, body } = req;\r\n  if (query && query[param]) {\r\n    return query[param];\r\n  }\r\n  if (body && body[param]) {\r\n    return body[param];\r\n  }\r\n};\r\n```\r\n\r\nYou’ll also note that the handlers are using a popular NPM package for HTTP requests, `axios`. Run `npm install axios --save` in your service root directory.\r\n\r\n### Current Folder structure\r\n\r\n```\r\nsls-az-func-rest-api\r\n|-- src\r\n    |-- handlers\r\n        |-- issues.js\r\n        |-- pulls.js\r\n    |-- utils.js\r\n|-- host.json\r\n|-- package.json\r\n|-- README.md\r\n|-- serverless.yml\r\n```\r\n\r\nNow we need to add our new handlers to the serverless configuration, which will now look like:\r\n\r\n```yaml\r\nservice: sls-az-func-rest-api \r\n \r\nprovider:\r\n  name: azure\r\n  location: West US 2\r\n \r\nplugins:\r\n  - serverless-azure-functions\r\n \r\npackage:\r\n  exclude:\r\n    - local.settings.json\r\n    - .vscode/**\r\n \r\nfunctions:\r\n  issues:\r\n    handler: src/handlers/issues.handler\r\n    events:\r\n      - http: true\r\n        x-azure-settings:\r\n          authLevel: anonymous\r\n  pulls:\r\n    handler: src/handlers/pulls.handler\r\n    events:\r\n      - http: true\r\n        x-azure-settings:\r\n          authLevel: anonymous\r\n```\r\n\r\n## Step 2.1: Test your API Locally\r\n\r\nRun the following command in your project directory to test your local service.\r\n\r\n```bash\r\nsls offline\r\n```\r\n\r\nThis will generate a directory for each of your functions with the file `function.json` in each of those directories. This file contains metadata for the “bindings” of the Azure function, and will be cleaned up when you stop the process. You shouldn’t try to change the bindings files yourself, as they will be cleaned up and regenerated from `serverless.yml`. If you make changes to your `serverless.yml` file, you’ll need to exit the process and restart. Changes to code, however, will trigger a hot reload and won’t require a restart.\r\n\r\nHere is what you can expect as output when you run `sls offline`:\r\n\r\n![alt text](https://s3-us-west-2.amazonaws.com/assets.blog.serverless.com/azure+plugin+update/offline.png)\r\n\r\nWhen you see the “Http Functions” in the log, you are good to invoke your local service.\r\n\r\n![alt text](https://s3-us-west-2.amazonaws.com/assets.blog.serverless.com/azure+plugin+update/urls.png)\r\n\r\nOne easy way to test your functions is to start up the offline process in one terminal, and then in another terminal, run:\r\n\r\n```bash\r\nsls invoke local -f {functionName} -p {fileContainingTestData.json}\r\n```\r\n\r\nLet’s create a file with some sample data at the root of our project, and we’ll just call it `data.json`:\r\n\r\n```json\r\n{\r\n  \"owner\": \"serverless\",\r\n  \"repo\": \"serverless-azure-functions\"\r\n}\r\n```\r\n\r\nLuckily, `owner` and `repo` are the same parameters expected by both the `issues` and `pulls` handlers, so we can use this file to test both.\r\n\r\nWe’ll keep our `offline` process running in one terminal. I’ll open up another (pro tip: use the “Split Terminal” in the VS Code integrated terminal), and run:\r\n\r\n```bash\r\nsls invoke local -f pulls -p data.json\r\n```\r\n\r\nHere’s my output:\r\n\r\n![alt text](https://s3-us-west-2.amazonaws.com/assets.blog.serverless.com/azure+plugin+update/invokeLocal.png)\r\n\r\nYou can see that it made a `GET` request to the locally hosted API and added the info from `data.json` as query parameters. There are no restrictions on HTTP methods, you would just need to specify in the CLI if it’s not a `GET`. (Example: `sls invoke local -f pulls -p data.json -m POST`)\r\n\r\nYou could also run a simple `curl` command that would accomplish the same thing:\r\n\r\n![alt text](https://s3-us-west-2.amazonaws.com/assets.blog.serverless.com/azure+plugin+update/curl.png)\r\n\r\nAnd here is the output in the terminal running the API. You can see our `console.log` statement from the handler output here:\r\n\r\n![alt text](https://s3-us-west-2.amazonaws.com/assets.blog.serverless.com/azure+plugin+update/handlerLog.png)\r\n\r\nWhen I’m done running the service locally, I’ll hit `Ctrl/Cmd + C` in the API terminal to stop the process. You can see that it cleans up those metadata files we discussed earlier:\r\n\r\n![alt text](https://s3-us-west-2.amazonaws.com/assets.blog.serverless.com/azure+plugin+update/cleanup.png)\r\n\r\n## Step 2.2: Deploy\r\n\r\n### Authentication\r\n\r\nThat’s all the configuration we need, so we’re ready to deploy this Function App. In order to deploy, we’ll need to authenticate with Azure. There are two options for authentication: interactive login and a service principal (which, if you are unfamiliar, is essentially a service account).\r\n\r\nAt first, when you run a command that requires authentication, the Interactive Login will open up a webpage for you to enter a code. You’ll only need to do this once. The authentication results are cached to your local machine.\r\n\r\nIf you have a service principal, you’ll set the appropriate environment variables on your machine, and the plugin will skip the interactive login process. Unfortunately, if you’re using a free trial account, your only option is a service principal. The process for creating one and setting up your environment variables is detailed in the [Azure plugin README](https://github.com/serverless/serverless-azure-functions#creating-a-service-principal).\r\n\r\n### Deploy Command\r\n\r\nWith configuration and authentication in place, let’s ship this thing. From the root of your project directory, run:\r\n\r\n`sls deploy`\r\n\r\nand watch the magic happen. Your app will be packaged up into a `.zip` file, which will be located in the `.serverless` directory at the root of your project. From there, an Azure resource group will be created for your application, containing things like your storage account, Function App, and more. After the resource group is created, the zipped code will be deployed to your newly created function app and the URLs for your functions will be logged to the console.\r\n\r\n![alt text](https://s3-us-west-2.amazonaws.com/assets.blog.serverless.com/azure+plugin+update/deploy+(1).png)\r\n\r\n## Step 2.3 Invoke Deployed Function\r\n\r\nWe can invoke a deployed function in the same way we invoked our local function, just without the `local` command:\r\n\r\n```\r\nsls invoke -f pulls -p data.json\r\n```\r\n\r\n![alt text](https://s3-us-west-2.amazonaws.com/assets.blog.serverless.com/azure+plugin+update/invoke.png)\r\n\r\n## (Optional) Step 2.4: Cleanup\r\n\r\nIf you have been following this tutorial and would like to clean up the resources you deployed, you can simply run:\r\n\r\n```\r\nsls remove\r\n```\r\n\r\nBE CAREFUL when running this command. This will delete your entire resource group.\r\n\r\n## Additional Steps\r\n\r\nStay tuned for future posts walking you through other steps of setting up your service, including adding [API Management](https://azure.microsoft.com/en-us/services/api-management/) configuration, quality gates like linting and unit tests, adding Webpack support, CI/CD and more.\r\n\r\nAlso, if you're going to be at ServerlessConf 2019 in NYC, the Microsoft team is putting on a [Azure Serverless Hands-on Workshop](http://aka.ms/nycworkshop) on October 7th from 8:30 am to 5:00 pm.\r\n\r\n## Contributing\r\n\r\nWe’re eager to get your feedback on the `serverless-azure-functions` plugin. Please [log issues on the GitHub repo with any bug reports or feature requests](https://github.com/serverless/serverless-azure-functions/issues/new/choose). Or better yet, fork the repo and open up a [pull request](https://github.com/serverless/serverless-azure-functions/pulls)!\r\n","data":{"title":"How to Create a REST API with Azure Functions and the Serverless Framework - Part 1","date":"2019-09-17T00:00:00.000Z","path":"serverlesspart1"},"isEmpty":false,"excerpt":""},"serverlesspart2":{"content":"\r\n#### Overview\r\n\r\n(_See the [original post here](https://serverless.com/blog/serverless-azure-functions-v2)._)\r\n\r\nNow that you've created and deployed a basic API from [Part 1](https://serverless.com/blog/serverless-azure-functions-v1), let's take a few more steps towards making that API more resilient and secure. This post will still be based on the [example repo](https://github.com/tbarlow12/sls-az-func-rest-api), and will follow the same \"commit-per-step\" format as [Part 1](https://serverless.com/blog/serverless-azure-functions-v1), which contains Steps 1 and 2.\r\n\r\nTo pick up where we left off in the example repo (after having completed Step 2), run:\r\n\r\n```bash\r\n# Assumes you've already forked the repo\r\n$ git clone https://github.com/<your-github-name>/sls-az-func-rest-api && git checkout cf46d1d\r\n```\r\n\r\n#### Step 3: Add unit testing and linting - (commit [465ecfe](https://github.com/tbarlow12/sls-az-func-rest-api/commit/465ecfe04bda8d4d5ac7c9c5ce31557a8993408f))\r\n\r\nBecause this isn't a blog post on unit tests, linting or quality gates in general, I'll just share the tools that I'm using and the quality gates that I added to the repository. Feel free to use them as stubs for your own future tests or lint rules.\r\n\r\nFor unit tests, I'm using the [Jest](https://jestjs.io/) test runner from Facebook. I've used it for several projects in the past and have never had any issues. Jest tests typically sit alongside the file they are testing, and end with `.test.js`. This is configurable within [`jest.config.js`](https://github.com/tbarlow12/sls-az-func-rest-api/commit/465ecfe04bda8d4d5ac7c9c5ce31557a8993408f#diff-2d0cd5d10b9604941c38c6aac608178a), which is found at the root of the project.\r\n\r\nBecause my code makes REST calls via `axios`, I'm using the `axios-mock-adapter` to mock the request & response. The tests that I wrote ([issues.test.js](https://github.com/tbarlow12/sls-az-func-rest-api/commit/465ecfe04bda8d4d5ac7c9c5ce31557a8993408f#diff-fb5daf13ab24c55eef4f041fc89c5025) and [pulls.test.js](https://github.com/tbarlow12/sls-az-func-rest-api/commit/465ecfe04bda8d4d5ac7c9c5ce31557a8993408f#diff-29c6cbdb5c35cdd4da7f67589ae7121a)) run some simple checks to make sure the correct URLs are hit and return the expected responses.\r\n\r\nFor linting, I'm using [ESLint](https://eslint.org) with a very basic configuration, found in [`.eslintrc.json`](https://github.com/tbarlow12/sls-az-func-rest-api/commit/465ecfe04bda8d4d5ac7c9c5ce31557a8993408f#diff-df39304d828831c44a2b9f38cd45289c). To run a lint check, you can run:\r\n\r\n```bash\r\n$ npm run lint\r\n```\r\n\r\nMany errors can be fixed automatically with:\r\n\r\n```bash\r\n$ npm run lint:fix\r\n```\r\n\r\nRun your tests with:\r\n\r\n```bash\r\n$ npm test\r\n```\r\n\r\nFor more details, take a look at the [commit in the example repo](https://github.com/tbarlow12/sls-az-func-rest-api/commit/465ecfe04bda8d4d5ac7c9c5ce31557a8993408f) or check out the commit locally\r\n\r\n```bash\r\n$ git checkout 465ecfe\r\n```\r\n\r\n#### Step 4: Add basic API Management Configuration - (commit [c593308](https://github.com/tbarlow12/sls-az-func-rest-api/commit/c593308efc5a60e2701ec97122564592072080e2))\r\n\r\nThis was one of the first features we implemented into the `v1` of the `serverless-azure-functions` plugin. because most Azure Function Apps are REST APIs, and it's hard to have a real-world API in Azure without [API Management](https://azure.microsoft.com/en-us/services/api-management/).\r\n\r\nIf you have no special requirements for API Management, the plugin will actually generate the default configuration for you if you just include:\r\n\r\n```yaml\r\n...\r\nprovider:\r\n    ...\r\n    apim: true\r\n```\r\n\r\nThat's exactly what I did for [Step 4](https://github.com/tbarlow12/sls-az-func-rest-api/commit/c593308efc5a60e2701ec97122564592072080e2). Also, because we want API Management to be the only entry point for our API endpoints, I also changed each function's `authLevel` to `function`. This requires a function-specific API key for authentication. You can see in the screenshot what happens in the first command, when I try to `curl` the original function URL. I get a `401` response code. But when I hit the URL provided by API Management, I get the response I expect:\r\n\r\n![alt text](https://s3-us-west-2.amazonaws.com/assets.blog.serverless.com/azure-functions-part2/apim_curl.jpg)\r\n\r\nFor more details on `authLevel`, check out the [trigger configuration docs](https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-http-webhook#trigger---configuration).\r\n\r\n##### Consumption SKU\r\n\r\nOne important thing to note is that the API Management configuration will default to the `consumption` SKU, which [recently went GA](https://azure.microsoft.com/en-ca/updates/azure-api-management-consumption-tier-is-now-generally-available/). For now, the only regions where `Consumption` API Management is allowed are:\r\n\r\n- North Central US\r\n- West US\r\n- West Europe\r\n- North Europe\r\n- Southeast Asia\r\n- Australia East\r\n\r\nIf you are deploying to a region outside of that list, you will need to specify a different SKU (`Developer`, `Basic`, `Standard` or `Premium`) within the `apim` configuration, which will be demonstrated in the next section.\r\n\r\nDeploy your updates:\r\n\r\n```bash\r\n$ sls deploy\r\n```\r\n\r\n#### Step 5: Add more advanced API Management Configuration - (commit [38413a0](https://github.com/tbarlow12/sls-az-func-rest-api/commit/38413a03100a65c423dc18ab47754471a4c6f245))\r\n\r\nIf you need a few more knobs to turn when configuring your API Management instance, you can provide a more verbose configuration. Here is the verbose config I added to the sample repo (the `...` means the rest of the config for that section stayed the same):\r\n\r\n```yaml\r\nservice: sls-az-func-rest-api\r\n\r\nprovider:\r\n  ...\r\n  apim:\r\n    apis:\r\n      - name: github-api\r\n        # Require an API Key if true\r\n        subscriptionRequired: false\r\n        displayName: Github API\r\n        description: The GitHub API\r\n        protocols:\r\n          - https\r\n        # Defaults to /api\r\n        path: github\r\n        # Azure resource tags\r\n        tags:\r\n          - apimTag1\r\n          - apimTag2\r\n        authorization: none\r\n    backends:\r\n      - name: github-backend\r\n        url: api/github\r\n    cors:\r\n      allowCredentials: false\r\n      allowedOrigins:\r\n        - \"*\"\r\n      allowedMethods:\r\n        - GET\r\n        - POST\r\n        - PUT\r\n        - DELETE\r\n        - PATCH\r\n      allowedHeaders:\r\n        - \"*\"\r\n      exposeHeaders:\r\n        - \"*\"\r\n...\r\n\r\nfunctions:\r\n  issues:\r\n    ...\r\n    apim:\r\n      api: github-api\r\n      backend: github-backend\r\n      operations:\r\n        - method: get\r\n          urlTemplate: /issues\r\n          displayName: GetIssues\r\n  pulls:\r\n    ...\r\n    apim:\r\n      api: github-api\r\n      backend: github-backend\r\n      operations:\r\n        - method: get\r\n          urlTemplate: /pulls\r\n          displayName: GetPullRequests\r\n```\r\n\r\nIf you did not want the `Consumption` SKU of API Management, you would need to have a verbose configuration and specify the `sku` as:\r\n\r\n```yaml\r\nprovider:\r\n  ...\r\n  apim:\r\n    ...\r\n    sku:\r\n      name: {Consumption|Developer|Basic|Standard|Premium}\r\n```\r\n\r\nThe example just uses the default and deploys to region(s) where Consumption API Management is currently available.\r\n\r\nDeploy your updates:\r\n\r\n```bash\r\n$ sls deploy\r\n```\r\n\r\n#### (Optional) Step 5.1: Revert back to basic API Management configuration - (commit [4c5803f](https://github.com/tbarlow12/sls-az-func-rest-api/commit/4c5803f1e5adf21befbeac8e91cac4552b4f9c1c))\r\n\r\nTo make the demo simple and easy to follow, I'm going to revert my `apim` configuration back to the defaults:\r\n\r\n```yaml\r\napim: true\r\n```\r\n\r\nYou might be able to do the same, depending on your requirements.\r\n\r\n#### Step 6: Add Webpack configuration - (commit [1aefac7](https://github.com/tbarlow12/sls-az-func-rest-api/commit/1aefac7e5ed99db009632724c6a70c9cb3d29bf8))\r\n\r\n[Webpack](https://webpack.js.org/) dramatically reduces the packaging time as well as the size of your deployed package. After making these changes, your packaged Function App will be optimized with Webpack (You can run `sls package` to package it up or just run `sls deploy` which will include packaging as part of the lifecycle).\r\n\r\nJust as an example, even for this very small application, my package size went from **324 KB** to **28 KB**.\r\n\r\nTo accomplish this, we'll use another awesome Serverless plugin, [`serverless-webpack`](https://github.com/serverless-heaven/serverless-webpack) to make Webpacking our Azure Function app really easy.\r\n\r\nFirst thing you'll want to do, assuming you're working through this tutorial in your own git repository, is add the generated Webpack folder to your `.gitignore`\r\n\r\n```yaml\r\n# .gitignore\r\n...\r\n# Webpack artifacts\r\n.webpack/\r\n```\r\n\r\nNext, we'll need to install 3 packages from npm:\r\n\r\n```bash\r\n$ npm i serverless-webpack webpack webpack-cli --save-dev\r\n```\r\n\r\nThen we'll add the plugin to our `serverless.yml`:\r\n\r\n```yaml\r\nplugins:\r\n  - serverless-azure-functions\r\n  - serverless-webpack\r\n```\r\n\r\nAnd then copy this exact code into `webpack.config.js` in the root of your service directory:\r\n\r\n```javascript\r\nconst path = require(\"path\");\r\nconst slsw = require(\"serverless-webpack\");\r\n\r\nmodule.exports = {\r\n  entry: slsw.lib.entries,\r\n  target: \"node\",\r\n  output: {\r\n    libraryTarget: \"commonjs2\",\r\n    library: \"index\",\r\n    path: path.resolve(__dirname, \".webpack\"),\r\n    filename: \"[name].js\"\r\n  },\r\n  plugins: [],\r\n};\r\n```\r\n\r\nAnd just like that, your deployed Azure Function apps will be webpacked and ready to go.\r\n\r\n![alt text](https://media.giphy.com/media/zcCGBRQshGdt6/giphy.gif)\r\n\r\n#### Step 7: Enable Serverless CLI configuration - (commit [4cb42fd](https://github.com/tbarlow12/sls-az-func-rest-api/commit/4cb42fdf17d7793a3ac9660bb43f28e8fe2d46d5))\r\n\r\nIf you're running a real-life production service, you will most likely be deploying to multiple regions and multiple stages. Maybe merges to your `dev` branch will trigger deployments to your `dev` environment, `master` into `prod`, etc. I'll show you an example of that in Step 8. To accomplish CLI-level configurability, we need to make a few changes `serverless.yml`.\r\n\r\n```yaml\r\nprovider:\r\n  region: ${opt:region, 'West US'}\r\n  stage: ${opt:stage, 'dev'}\r\n  prefix: ${opt:prefix, 'demo'}\r\n```\r\n\r\nAs you might have guessed, the values `West US`, `dev` and `demo` are my default values. If I wanted to deploy my service to `North Central US` and `West Europe`, but keep everything else the same, I would run:\r\n\r\n```bash\r\n$ sls deploy --region \"North Central US\"\r\n$ sls deploy --region \"West Europe\"\r\n```\r\n\r\nWe could do similar operations with `--prefix` and `--stage`. Now let's create a pipeline that actually does this.\r\n\r\n#### Step 8: Add CI/CD (with Azure DevOps) - (commit [a8fabf6](https://github.com/tbarlow12/sls-az-func-rest-api/commit/a8fabf6faa30f7ceab7c18395a5c69c21abd4640))\r\n\r\nFor the CI/CD on my sample repo, I'm using Azure DevOps, but it would work the same on any other service you want to use. If you want to use Azure DevOps for an open-source project, [here are a few steps to get started](https://docs.microsoft.com/en-us/azure/devops/organizations/public/about-public-projects?view=azure-devops#get-started-with-a-public-project)\r\n\r\nNo matter the CI/CD environment, here is what we are looking to accomplish:\r\n\r\n1. Install dependencies\r\n2. Validate the changes (run quality gates)\r\n3. Deploy the service\r\n\r\nThese steps can all be accomplished in just a few CLI commands. At bare minimum, we'll want to run something like:\r\n\r\n```bash\r\n# Clean install\r\nnpm ci\r\n# Runs tests and linting\r\nnpm test\r\n# Serverless not contained within dev dependencies to avoid conflicts\r\n# because most users have it installed globally on their dev machine\r\nnpm i serverless -g\r\n# Deploy service\r\nsls deploy\r\n```\r\n\r\nThere are a lot more bells and whistles we could add, but that's essentially what it boils down to. Of course, we'll need authentication in whatever system we're deploying from, and that's where the [service principal](https://github.com/serverless/serverless-azure-functions#creating-a-service-principal) will come in. I'll show you how to use the service principal in the `deploy.yml` pipeline below.\r\n\r\nFor my pipelines, I'm actually going to split up my CI and CD into `unit-tests.yml` and `deploy.yml`. Unit tests will be run on PRs into `master` or `dev` (this is assuming there are branch policies in place to prevent devs from pushing straight to either branch). Deployment will be run on commits (merges) to `master`.\r\n\r\n##### Unit Tests\r\n\r\n```yaml\r\n# pipelines/unit-tests.yml\r\n\r\n# Only run on Pull Requests into `master` or `dev`\r\npr:\r\n  branches:\r\n    include:\r\n    - master\r\n    - dev\r\n\r\n# Run pipeline on node 8 and 10 on Linux, Mac and Windows \r\nstrategy:\r\n  matrix:\r\n    Linux_Node8:\r\n      imageName: 'ubuntu-16.04'\r\n      node_version: 8.x\r\n    Linux_Node10:\r\n      imageName: 'ubuntu-16.04'\r\n      node_version: 10.x\r\n    Mac_Node8:\r\n      imageName: 'macos-10.14'\r\n      node_version: 8.x\r\n    Mac_Node10:\r\n      imageName: 'macos-10.14'\r\n      node_version: 10.x\r\n    Windows_Node8:\r\n      imageName: 'win1803'\r\n      node_version: 8.x\r\n    Windows_Node10:\r\n      imageName: 'win1803'\r\n      node_version: 10.x\r\n\r\n# https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops#use-a-microsoft-hosted-agent\r\npool:\r\n  vmImage: $(imageName)\r\n\r\nsteps:\r\n- task: NodeTool@0\r\n  inputs:\r\n    versionSpec: $(node_version)\r\n  displayName: 'Install Node.js'\r\n\r\n# Make pipeline fail if tests or linting fail, linting occurs in `pretest` script\r\n- bash: |\r\n    set -euo pipefail\r\n    npm ci\r\n    npm test\r\n  displayName: 'Run tests'\r\n```\r\n\r\n##### Deployment\r\n\r\n```yaml\r\n# pipelines/deploy.yml\r\n\r\ntrigger:\r\n  branches:\r\n    include:\r\n    - master\r\n\r\n# https://docs.microsoft.com/en-us/azure/devops/pipelines/library/variable-groups?view=azure-devops&tabs=yaml\r\nvariables:\r\n- group: sls-deploy-creds\r\n\r\njobs:\r\n\r\n- job: \"Deploy_Azure_Function_App\"\r\n  timeoutInMinutes: 30\r\n  cancelTimeoutInMinutes: 1\r\n\r\n  pool:\r\n    vmImage: 'ubuntu-16.04'\r\n\r\n  steps:\r\n  - task: NodeTool@0\r\n    inputs:\r\n      versionSpec: 10.x\r\n    displayName: 'Install Node.js'\r\n\r\n  - bash: |\r\n      npm install -g serverless\r\n    displayName: 'Install Serverless'\r\n    # Deploy service with prefix `gh`, stage `prod` and to region `West Europe`\r\n  - bash: |\r\n      npm ci\r\n      sls deploy --prefix gh --stage prod --region \"West Europe\"\r\n    env:\r\n      # Azure Service Principal. Secrets need to be mapped here\r\n      # USE THIS EXACT TEXT, DON'T COPY/PASTE YOUR CREDENTIALS HERE.\r\n      # Azure DevOps will use the variables within\r\n      # the variable group `sls-deploy-creds` to replace all the $() values\r\n      AZURE_SUBSCRIPTION_ID: $(AZURE_SUBSCRIPTION_ID)\r\n      AZURE_TENANT_ID: $(AZURE_TENANT_ID)\r\n      AZURE_CLIENT_ID: $(AZURE_CLIENT_ID)\r\n      AZURE_CLIENT_SECRET: $(AZURE_CLIENT_SECRET)\r\n    displayName: 'Deploy Azure Function App' \r\n```\r\n\r\nNotice [this line](https://github.com/tbarlow12/sls-az-func-rest-api/blob/master/pipelines/deploy.yml#L30) in the deployment pipeline that leverages our setup from Step 7. You might have multiple pipelines for the different stages, you might dynamically infer these values from the branch name or you might just provide the values as environment variables. The point of the setup in Step 7 was to provide you the flexibility to deploy your service to wherever you see fit at the time, without needing to change your `serverless.yml` file.\r\n\r\n#### Concluding Thoughts\r\n\r\nA big part of our reason for investing time and effort into the `serverless-azure-functions` plugin was so that developers could easily deploy Azure Functions to solve more real-world, business-level scenarios. We hope that as you use the tool and discover areas for improvement that you'll [file issues on the repo](https://github.com/serverless/serverless-azure-functions/issues/new/choose) or even open up a [pull request](https://github.com/serverless/serverless-azure-functions/pulls).\r\n","data":{"title":"How to Create a REST API with Azure Functions and the Serverless Framework - Part 2","date":"2019-10-1","path":"serverlesspart2"},"isEmpty":false,"excerpt":""},"mistakes":{"content":"\r\nNow that I've click-baited you into opening this post, let me just reassure you of a few things:\r\n\r\n1. I still have my job\r\n2. The Azure subscription was just a development subscription, so no $ was lost\r\n3. An irresponsible amount of GIFs will be used in this post.\r\n\r\n![alt text](https://media.giphy.com/media/4PT6v3PQKG6Yg/giphy.gif)\r\n\r\n## The Discovery\r\n\r\nIt was a crisp, autumn work-from-home kind of Friday. After having breakfast with my family, I went downstairs to my office and cracked open the laptop to begin another wonderful day of writing code...\r\n\r\nThe afternoon prior, I had deployed an Azure Function that would be running a [Cloud Custodian](https://cloudcustodian.io/) policy to clean up our Azure Subscription. We had a lot of test resources that needed to be removed, so I asked our team to tag any resource groups they needed with `CreatedBy` and their email address for notifications. They all looked through the subscription and tagged their resource groups accordingly. I told them that early Friday morning, I would run a scrub of all resource groups and delete any that did not have owners, and that was the policy that was deployed... or so I thought.\r\n\r\nThat morning, to my utter shock and horror, I opened the Azure portal to discover _**one**_ resource group... `cloud-custodian`.\r\n\r\nSo many questions started racing through my mind. How did this happen? Where did I go wrong? What had caused this lone surviving resource group to cannibalize all of his innocent, appropriately-tagged brothers? Panic had already begun to take over.\r\n\r\nI opened up the repository containing the policies I had written, and that's when I saw it. I had neglected to update the test tag I had been using... `CreatorEmail`. I had also been testing a policy that would send a weekly email to the members of my team with a summary of their resource groups, which would enable them to do a quick scan and go remove any they didn't need anymore. I created the `CreatorEmail` tag to test the notification system on the `cloud-custodian` resource group so that I wasn't spamming my whole team while I was testing the policy. At the end of the day, I ran a script that deployed all the policies I was working on. That test tag had been copied and pasted to the other policies I had deployed. I did read things through, but clearly not closely enough. I had deployed a rogue agent... I opened the doors wide open and let a monster into our house.\r\n\r\n## The Fallout\r\n\r\nClearly, this was not going to be a mistake that would fly under the radar, so I figured the sooner I got in front of this, the less likely my head would end up on a pike outside the Microsoft headquarters. I immediately called my manager to tell him what happened.\r\n\r\n![alt text](https://media.giphy.com/media/sS8YbjrTzu4KI/giphy.gif)\r\n\r\nHe was in another call, so we chatted online. I told him what had happened. I'm not sure he believed me until he opened the portal and witnessed the devastation for himself. _\"You're right... it nuked everything,\"_ he responded.\r\n\r\nAfter what seemed an appropriate moment of silence for the fallen resource groups, he was quick to point out that `a)` this is only a dev subscription and `b)` anything in the sub should be easily reproducible. He reminded me that everyone goes through something like this at some point, and this was a pretty low-stakes environment for it to happen. Then, like a mayor of a city ravaged by a natural disaster, he stated, _\"We can rebuild.\"_\r\n\r\nAfter the call with my manager, I called a couple team members to assess the extent of the damages. I called my tech lead and told him what had happened. He laughed. He told me about a time where he had deleted a production database early on in his career and reminded me of some of the same things my manager told me. We then made a plan for restoring some of the lost resource groups that were actually public facing.\r\n\r\nI decided it was time to tell the team. I wrote up a long email describing the details of what had happened and posted it in our chat channel as well. I was fully expecting a swift and brutal judgment worthy of my crimes.\r\n\r\n![alt text](https://media.giphy.com/media/qiDb8McXyj6Eg/giphy.gif)\r\n\r\nBut rather than _\"How could you?\"_, _\"How dare you?\"_ or other responses you might expect in such a circumstance, every member on the team simply reacted to my message with a single emoji:\r\n\r\n💪\r\n\r\nas if to say _\"Be Strong.\"_\r\n\r\nAnd that was pretty much it. After some of the initial rawness of the incident had worn off, we were able to laugh about it a little bit. A team member pointed out that until you break production, you're not a real engineer. I countered with the remark that if that was all it took, I would've done this a long time ago. I got to work restoring the damages, reached out to other developers that were using some of our deployed services and helped them get back up to speed.\r\n\r\n## Takeaways\r\n\r\n### Technical Empathy and a Blameless Culture\r\n\r\nOne of the surprising parts of this experience was the empathy shown by my colleagues. They were quick to point out times where similar things had happened to them or others and to remind me that it was an honest mistake. This kind of \"technical empathy\" is not only helpful, but essential in building successful, collaborative software teams that trust each other and work together. This is one example where the empathy of my teammates gave me the boost that I needed to get back up and start fixing things rather than wallow in my own self pity.\r\n\r\nTechnical empathy should be used in more than just response to disasters. For example, it is also useful in giving (and receiving) code reviews. Rather than belittling team members for making what we perceive to be a mistake in the code, we can try to understand why they felt they had to do what they did. There very well may be an obstacle that we, as reviewers, are unaware of. Technical empathy should also be used in reading legacy code. In our team at Microsoft, we work with dev teams of other companies to help them solve interesting challenges, usually related to Azure. As a byproduct of that, we get to see _a lot of new codebases_. Every time we crack one open, there's a little bit of apprehension (and even fear) about what we might find. Technical empathy can be applied here too. A popular article titled [\"The software engineer’s guide to asserting dominance in the workplace\"](https://medium.com/feature-creep/the-software-engineer-s-guide-to-asserting-office-dominance-ddea7b598df7) (satirically) recommends the following strategy for ramping up on a codebase when joining a new team:\r\n\r\n_\"Spend the rest of the day familiarizing yourself with the team’s codebase. Every five to ten minutes, let out a deep sigh and write something down on a notepad. Maintain a demeanor of mild disgust on your face that gets increasingly more annoyed as you browse through more and more of the code. Mumble words like “refactor” and “rewrite” under your breath. Start drawing random complex architectural diagrams on your whiteboard. By 3 PM you should be visibly angry. Eat some chili peppers to force yourself to sweat. At 4 PM, allow your rage to boil over and throw your last egg at the wall in a fit of rage. Slam your laptop closed and head home early._\r\n\r\nIt is easy to be critical when you're unaware of the constraints and difficulties encountered by other developers. Often times, on high-performing teams, if you have an idea within the first few seconds of looking at a problem, it's possible that other engineers might have tried the same approach. That's not to say you shouldn't share your ideas on how things could be better, but be hesitant about jumping to the conclusion that you're surrounded by morons and that you are the only one who is truly \"one with the code.\" For more info on the subject, visit [this article on how empathy is a technical skill](https://www.infoq.com/articles/empathy-technical-skill/).\r\n\r\nRather than becoming upset and demanding my immediate dismissal, my team responded with _\"Sorry that happened, it happens to all of **us**, what do we do to fix it?\"_ The phrase \"blameless culture\" became more than just a line in our team's working agreement.\r\n\r\n### Use the Buddy System\r\n\r\nFor any of you that ever went to any kind of summer camp, you know that one of the first rules they tell you is to never wander off alone. Bring a buddy along with you. If I would have just listened to my camp counselor and followed that simple rule, you wouldn't be reading this blog post right now.\r\n\r\nAs software engineers, asking others for help or to look over our work isn't always our natural inclination. We often see ourselves as a one-man army, equipped with a mechanical keyboard and multiple monitors, leaving a trail of dead bugs and shattered features in our wake.\r\n\r\n![alt text](https://media.giphy.com/media/TBOvwBGkQShnq/giphy.gif)\r\n\r\nTo counteract that behavioral tendency, we put up quality gates. On our team, in every repository we work with, we establish branch protection policies that prohibit anyone from pushing directly to `master` or even `dev`. We require pull requests that trigger CI pipelines and establish baseline coverage requirements for both the project as a whole and the current diff being submitted. (Side note on code coverage: We recognize that developers can \"game the system\" when it comes to code coverage, so the tests are reviewed with just as much scrutiny as the application code.)\r\n\r\nThese standards are required on every single project that we work on. All of this could have been so easily prevented if I had just asked for even one other pair of eyes to look over these basic policies before I had deployed them. Instead, I ignored the rules, wandered off into the wilderness by myself and got mauled by the proverbial bear of disaster.\r\n\r\nUPDATE: Now, these policies are deployed from a central build server via an Azure Pipeline, which is triggered on merges to the master branch of a repository that requires two approvals from members of the team in order to merge.\r\n\r\n### Be especially careful with irreversible actions\r\n\r\nPart of the tragedy of this episode was its finality. There was no commit to revert, no deployment to roll back. These resource groups were as lost as Black Widow after Endgame.\r\n\r\nA lot of what we do as software engineers is set up guard rails and fail-safes so that when things break, we have a quick way to return to the state we were in before the change. When we decide to venture outside the lines and do things that are irreversible, we should do so with care and hopefully, with a buddy ☝.\r\n\r\nUPDATE: Currently, in our Cloud Custodian policies, \"nuclear\" actions (like delete) are given a \"grace period\" of 7 days before they are enacted. The resources are tagged for the operation and an email is sent to the team member(s) responsible for the resource so that they can cancel the operation if necessary.\r\n\r\n### Automate, Automate, Automate\r\n\r\nFor several members of my team, this loss was almost trivial. Many of the resource groups were just a CLI execution or a pipeline run away from being restored. Sometimes we spend _too_ much time trying to automate tasks when we just need to stand something up and get unblocked, but when possible, use scripts, pipelines and templates to do the dirty work. It will save you (and probably your team) hours of work later on if that work needs to be replicated. It will allow you to focus on solving the cool problems instead of re-figuring out something you've done before.\r\n\r\n## Conclusion\r\n\r\nMistakes are part of software engineering and a part of life. I make them every day, and I don't expect that to stop any time soon. But I don't expect to make the same mistake twice. My all-time basketball hero, John Wooden, once said _\"Failure is not fatal, but failure to change might be.\"_ You don't have to let something like this happen to you. In fact, I highly recommend that you don't. Learn from my experience. Ask for another pair of eyes. Be careful if you're doing something irreversible. Set up recovery steps to back up your work. It will save you a lot of heartache and a lot of time someday.\r\n","data":{"title":"I Wiped Our Entire Azure Subscription...","date":"2019-10-4","path":"mistakes"},"isEmpty":false,"excerpt":""},"twentyquestions":{"content":"\r\nHi, I'm Tanner Barlow. I'm a software engineer on the Commercial Software Engineering team at Microsoft. I grew up in Salt Lake City, Utah, where I also attended school at the University of Utah (Go Utes!). I majored in Computer Science and helped start the school's first ever hackathon, HackTheU, with a few of my friends. I was asked to answer 20 questions regarding my experience working at Microsoft and what it's like to live in the great Pacific Northwest. If either of these topics interest you (primarily the first), read on.\r\n\r\n## 1. How are using Microsoft as a platform from your passions?\r\n\r\nI get to work on some pretty cool open-source projects at work. I get to work on a broad range of technologies and tools, spanning the stack. Our team does some traveling, so I bring my family on a lot of my work trips and often extend my stay to explore the different parts of the world we visit. We meet and work alongside other software engineers from all over the world. Our management encourages 20% projects (relevant side projects you work on with 20% of your time), some of which have actually evolved into open-source projects that we’ve worked on and contributed to. I've been able to attend a few conferences (our team sends us to one conference per year if we want to go).\r\n\r\n## 2. What is your favorite building on campus and why?\r\n\r\nThe Mixer – basically any kind of food you could want and a basketball court right outside.\r\n\r\n## 3. What's the most challenging part of your job?\r\n\r\nConstant change and needing to learn radically different tools & technologies in a short period of time. Our team works on a pretty broad range of stuff. For example, in the last year, I went from working on Cloud Custodian (Python) to working on VoTT (TypeScript, Electron, React) to working on the Azure Functions plugin for the Serverless Framework (TypeScript, Node) with a few small projects sprinkled in between.\r\n\r\n## 4. Myth or Not: Do you have to be an intern to secure a full-time role?\r\n\r\nMYTH. Of the 10 members on my team, 2 of us were interns at Microsoft. I loved my experience for two summers as an intern at Microsoft, but it's definitely not a requirement.\r\n\r\n## 5. Interview Prep 101, what is the best resource you would recommend?\r\n\r\nCracking the Coding Interview + LeetCode + Pramp\r\n\r\n## 6. What's one piece of career/personal advice you'd give you your younger self?\r\n\r\nGet up early and get things done before the rest of the day makes demands on your time. The first hour of my day is reserved for only the most important things, and it makes the rest of my day go so much better.\r\n\r\n## 7. What are ways that you feel empowered to give back to communities and how?\r\n\r\nThe donation matching + volunteer time matching ($25/hr) from Microsoft is an amazing benefit that I’ve used to give back to a local Boy Scout troop I’ve volunteered with.\r\n\r\n## 8. How did you decide to work at MSFT vs. another company?\r\n\r\nMSFT seemed more family-friendly than most of the companies I was interviewing with (I'm writing this in the middle of my 12 weeks of paternity leave). I felt like I could really grow in CSE, and I felt like there were a lot of people around me that would help me learn. Microsoft is huge, and I like the flexibility of being able to switch what I'm working on without leaving the company (Not happening any time soon, CSE is way too much fun). I also really identified with the vision of “empowering others” from Microsoft's mission statement.\r\n\r\n## 9. Who are your mentors? How did you select/build a relationship with mentor?  \r\n\r\nI have several mentors, but as I mentioned above, one of the reasons I picked Microsoft (and specifically, CSE) was because I felt like there were a lot of engineers that were willing and able to teach me. I get to work side by side with some of the smartest software engineers I've met, and I've learned a lot from them. One of my mentors is a manager on a peer team. We met on his first day joining the group at Microsoft's annual company-wide hackathon, and at the time, I was still trying to decide on whether or not to rejoin Microsoft after graduating. He gave me some sage wisdom and taught me more in those 3 days of coding side-by-side than I had learned in weeks of working in my day job. I decided that if I can work with people like that every day, that's a place I want to be. Since joining the team, we grab coffee (or hot chocolate for us non-coffee drinkers) every 2-3 weeks to chat about whatever’s going on in work and in life. He's got a lot of experience and knowledge to share, and I'm grateful to be able to benefit from it. Other mentors include my parents, church leaders and previous managers from my intern days at MSFT.\r\n\r\n## 10. In a quick snapshot, what do you do?\r\n\r\nSimply put, I write code with dev teams of Microsoft partners. For 3-5 months, our team pairs up with one of their dev teams and solve whatever interesting problem they are confronting at the time. This usually includes traveling to wherever they are in the world at least once. Because these companies all use some open-source tooling at some place in their stack, we do a lot of work on strategic open-source projects to support these efforts.\r\n\r\n## 11. In your mind, what makes a great software engineer?\r\n\r\nGrit, resourcefulness and humility. With those three things, most of the other skills can be acquired over time.\r\n\r\n## 12. What does a typical day look like as a software engineer? How much time do you spend coding? In meetings? etc. What is the size of your team? How does your manager contribute to your overall success?\r\n\r\nMy day starts early, I usually roll into the office around 5:45. I save the first few precious hours of solitude in the office strictly for writing, reading and reviewing code. The rest of my team trickles in throughout the morning, and we'll usually have standup around 10. These standup calls are often conference calls with another dev team somewhere else in the world, so that may be adjusted depending on their time zone. Aside from standup, there's usually one or two other meetings at some point throughout the day, and we do a lot of impromptu meetings to discuss design or feedback from a code review. Our team has 10 engineers, but we’re often split in 2 or 3 squads depending on the projects we have going at the time. My manager is actually right there in the weeds with us – coding alongside us just like other devs on the team. He does a great job of making sure we all have opportunities to stretch and grow.\r\n\r\n## 13. Can you give me more insight into internal mobility? (i.e. how common is it to move teams, how did you do it? Does the power of networking really work?)\r\n\r\nI worked as an intern in the Windows organization for 2 years, and joined this team when I came on full-time. Not a difficult change, I just talked to a manager a few times and did the OneWeek hackathon with him and a few others on his team to see if it would be a good fit. It was 😊\r\n\r\n## 14. If you were a former intern, what was your intern project?\r\n\r\nI interned for two summers, and my projects were 1) Automating identification of actionable feedback from Windows users using an internal NLP tool and 2) K-means clustering pipeline of windows users based on telemetry received from their machine.\r\n\r\n## 15. If you weren’t a Software Engineer/Program Manager, what would you be?\r\n\r\nEither the Assistant to the Regional Manager of a local paper supply company or an architect at Vandelay Industries.\r\n\r\n## 16. What is your favorite café/restaurant in the Seattle area?\r\n\r\nWell, we live in Everett, so I'll go with Chops (Bulgorrito… It’s exactly what it sounds like)\r\n\r\n## 17. What is something that you do outside of work to re-energize?\r\n\r\nCook with my wife, play basketball with my friends, play with my 2 sons (ages 2 and 1 week), binge watch The Office or Parks and Rec.\r\n\r\n## 18. Describe your ideal day in Seattle?\r\n\r\nSummer day on the beach (probably Jetty Island) with my family. Ride the bus into Seattle for a Mariners game, complete with a Seattle dog, garlic fries and post-game fireworks\r\n\r\n## 19. What's your favorite way to eat a potato?\r\n\r\nSliced up and fried into 3-5 inch cubic strands of pure goodness. Otherwise known as french fries. Preferably next to a burger. Preferably from Dick’s drive in\r\n\r\n## 20. If you had a superpower, what would it be and why?\r\n\r\nSleep Manipulation (think Mantis from Avengers) so that I could make my kids sleep when they're supposed to. Either that or flight.\r\n","data":{"title":"20 Questions - Working at Microsoft","date":"2019-10-15T00:00:00.000Z","path":"twentyquestions"},"isEmpty":false,"excerpt":""},"tasks":{"content":"\r\nThe story is told of a farmer who set out to plow the southern field one spring morning. Although it was important work, he did not assess in advance exactly what had to be done or form a plan for how he was going to do it. He had started early by oiling his tractor. He knew he needed more oil, so he went to the barn to get it. On the way to the barn, he noticed that the pigs had not been fed. This sent him to the cradle of corn, where he saw some sacks. That reminded him that the potatoes were sprouting, so he started toward the potato hole. While passing by the wood pile, he remembered that his wife wanted some firewood for the house. While he was collecting logs, he saw a chicken that was sick, so he left the wood and went to his aid. When night came, the tractor was still in the barn, and the field to the south was left unplowed. The poor farmer had worked hard all day, but had not accomplished the main thing he had to do that day.\r\n\r\nI'm hesitant to write this post for a number of reasons. First, I don't want this to come off as prescriptive in any way. I'm a strong believer that, when it comes to productivity, people should find whatever works best for them, and then do it. Second, I don't want to give the impression that I believe myself to be an expert in the psychology of productivity or a master of planning and executing tasks in my own life. I've learned a lot of things from a lot of smart people, and I've seen the benefits of putting their ideas into practice. This post is just a medium for me to share some of the things that I've learned in my years of research and experimentation with my own productivity. Finally, I don't want to give the impression that I am perfect at implementing this system all the time. I've learned that life is messy and crazy for all of us. If my son wakes up in the middle of my Weekly Planning session, I can't just ask him to hold off for another 46 minutes while I finish estimating my tasks for the week. Like you, I am constantly juggling the different pieces of my life, and this system has made it easier to keep them all afloat.\r\n\r\n![alt text](https://i.makeagif.com/media/5-01-2015/ZUZocx.gif)\r\n\r\nIt may seem like a lot of overhead, but the main purpose of all of this is to free up my mind to allow me to *really* focus on one thing at a time. Having these things in place gives me the assurance that I'm doing exactly what I should be doing at that time, and that all important tasks will get done when the time is right.\r\n\r\nInstead of describing my whole process for capturing, processing, planning and executing my tasks in a step-by-step fashion, I just want to share some of the tools and habits that have been helpful to me. With the current outbreak of COVID-19 and all that comes with it, especially working from home 100% of the time, I've found these to be more important than ever. I hope some of this is helpful for you, too. I'd also add the big disclaimer that any piece of this system is subject to, and will probably undergo, change at some point in the future. It's constantly evolving as I learn new ways to be more productive and as I adapt to life's ever-changing circumstances.\r\n\r\nAlso, fair warning, I love talking about this subject. So if you're in, then settle in and get comfortable. You've been warned.\r\n\r\n![alt text](https://media.giphy.com/media/3P0oEX5oTmrkY/giphy.gif)\r\n\r\n## My Task Board\r\n\r\n[Trello](https://trello.com/) is the main hub for all of my productivity tools. All of my tasks are found here. I love Trello because it's genuinely satisfying to use, it's easy to see and update the status of each task and it's the closest digital analog (no pun intended) to a \"sticky note task board\" as I've used. There's also a pretty rich ecosystem of tools that add additional features to Trello. I'll discuss a few of them below.\r\n\r\nI've played around with many other ideas for managing my own tasks - hierarchical lists, flat lists, paper notebooks, sticky notes, etc. I've also used many tools in my career for managing tasks on a team, such as GitHub projects, Jira, Azure DevOps, physical sticky note boards and more. I still use some of these tools for certain scenarios, but Trello is by far my favorite. I really enjoy being able to have all my tasks in one place while still being able to organize those tasks into discrete buckets and easily move tasks through various phases of its lifecycle. My Trello board basically has the following list structure:\r\n\r\n- Triage\r\n- This Week\r\n- Today\r\n- Waiting For\r\n- Done\r\n- *...Categorical Backlog* (I'll give some category examples later)\r\n- Things I'd like to do\r\n\r\nHere's an explanation of what these lists do for me:\r\n\r\n`Triage` - This is the birthplace of *most* my tasks. If there are tasks that come up that I *know* are urgent and *must* be completed either today or this week, I'll just put them directly in the appropriate list, but they almost always start here. By having this one place where all the ideas are collected, I can be sure that I'm not missing a captured idea just because it's hidden in the bottom of one of my categorical lists. It also forces me to prioritize incoming tasks on at least a daily basis. I keep this as the first list on my board so that I can trust myself to deal with incoming tasks frequently. I've added other tools that make it easy to capture thoughts and tasks in this list wherever I am (see \"Capturing Tools\" below). Because my Trello board is my task hub, if a task or thought can make it to my Trello board, I can be 100% certain that I'll be forced to deal with it at some point. Here are a few examples of things that are in my list this morning:\r\n\r\n- Print out my son's insurance card for his next checkup\r\n- Set up a meeting with a co-worker to discuss 3D model decimation\r\n- Integration tests for .NET Azure functions\r\n- Order a Mother's day gift for Mom\r\n\r\nAs you can see, the tasks can be from any part of my life. That's the point. I have one funnel through which all my tasks must pass. It allows me to capture everything without burdening my brain all the time about where each category of task should live. During the triage process, I'll add a label, a due date, an estimate of how long this task will take, and then put it in it's appropriate spot. Often times, as part of the triage process, a task name will be changed, since I may have just tried to quickly capture the idea. Just as often, tasks will be split out into multiple, more concrete tasks. As long as `Triage` captures the essence of the task, I can spend more time in my planning sessions defining how I want it to happen.\r\n\r\n`This Week` - This list represents the body of work that I've committed to during the week. Having this list enables a quicker daily planning session, as I don't need to scan the entire board to decide which things I want to get done today. Every task in this list will have a due date as well as a story point estimate. I'll discuss in more detail in my Weekly Planning section below.\r\n\r\n`Today` - My `Today` list is the list of tasks I've committed to do today. This, to me, is the most important list because if I'm not actually *doing* something *today*, what's the point in planning at all? I try to make sure that tasks are pared down enough that I will be able to accomplish them within the day, and I try to make sure the number of tasks I need to do every day does not exceed my ability to accomplish them. I have a [Butler](https://help.trello.com/article/1198-an-intro-to-butler) policy that runs every night removes any remaining task from `Today` and puts it in `This Week`, so I can start my day with a clean slate, and deliberately choose the tasks that I will do each day. Daily planning is a crucial component to keeping this list up to date and useful, and I'll discuss this more below.\r\n\r\n`Waiting For` - Nothing generates more conscious or sub-conscious frustration for me than to see a task in my list that I can do nothing about. By having a landing spot for tasks that require an action/event outside of my control, I can let my mind rest, knowing that I've done all that I can for now. This list is also scanned during my morning planning just in case that action/event has happened and I can move forward to finishing the task.\r\n\r\n`Done` - This, perhaps to your great surprise, holds the tasks that are done. In the past, I've just archived the card when it's done, but I found that I get a lot more joy out of moving the card over to the done column than letting it disappear in to the digital void. Plus, at the end of the week, I have a [Butler](https://help.trello.com/article/1198-an-intro-to-butler) policy (again, later) in place to generate a report of everything that I did during the week, send me an email with the results and then ceremoniously archive each card to clear space for the coming week. It's magical.\r\n\r\n`Categorical Backlog` - Here are a few examples of the lists that comprise my \"categorical backlog\" and a few examples of what's currently in each:\r\n\r\n- `Work`\r\n  - Automated integration test pipeline for [serverless-azure-functions](https://github.com/serverless/serverless-azure-functions/)\r\n  - Pro and con comparison between Kafka, RabbitMQ, MSMQ and any other on-prem AMQP system\r\n- `Church`\r\n  - Organize speakers for congregational broadcast next week\r\n- `Digital` (things I can do anywhere from my laptop)\r\n  - Finish menu for my wife's birthday\r\n  - Add my IRA contributions to my taxes\r\n- `Errands` (things I can only do out and about)\r\n  - Refills for Pilot G2 07 Pens\r\n  - Recycle old laptop\r\n- `Home Projects` (things I can only do at home)\r\n  - Put up new picture in son's room\r\n  - Get information from heater for smart thermostat rebate\r\n- `Side Projects` (mostly coding projects that are not *directly* part of my job)\r\n  - Azure DevOps webhook for automatically adding tasks to Trello when assigned to me\r\n  - [Clover](https://www.npmjs.com/package/clvr) enhancement - allow for RegEx validation\r\n- `Learning` (articles to read, topics to study, tutorials to do)\r\n  - Read \"How Will You Measure Your Life\" again - on paper\r\n  - Read blog post on Cloud Design Patterns\r\n- `Planning` (big picture planning, improvements to my process, etc.)\r\n  - Create a more deliberate nightly routine\r\n  - Refine our family emergency preparedness plan\r\n\r\nI used to just have one long backlog of tasks that got prioritized each week. I switched to keeping categorical lists for two reasons:\r\n\r\n1. More **compartmentalization**. I really like to be able to focus on the thing I want to focus on when I want to focus on that thing. If I can look at one list that contains all my pending tasks for that context (outside of the tasks that need to be done today or this week), it just makes me feel warm inside.\r\n2. Just in case I'm in the **\"right place, right time\"** to do a task that I didn't necessarily plan on. For example, I have an `Errands` list. If I'm out and about with my two little boys and want to give my wife a little extra time to just sit in peace without a baby in her arms or a toddler climbing all over her, I'll pull up the list and see if there is anything we can go do together. Or, if I'm at work and get some unexpected extra time between meetings for a quick task, I can check my `Work` list to see if there's anything that can fit in that amount of time.\r\n\r\n`Things I'd like to do` - Often times, a task will come to mind that is neither urgent nor super important, but something that would be nice to have done at some point. For example, right now in this list, I have tasks for several blog posts I'd like to write, one for reorganizing my workout playlist and another to start digitizing some of my journals.\r\n\r\nTo make sure these categories are not lost as the tasks move through the different lists, I have [Butler](https://help.trello.com/article/1198-an-intro-to-butler) actions (once again, you'll read more about this later... stop trying to jump ahead) that automatically apply the appropriate label to cards as they are moved into the list. This gives me the capability of filtering my entire board to see only tasks with that label, even if they are no longer in their categorical list. For example, when I'm at work, it's nice to see work-related tasks that I'm doing `This Week` or `Today` without having to scan through the other tasks in those lists.\r\n\r\n## Capturing Tools\r\n\r\nI've found that quickly and frequently capturing tasks, thoughts and ideas can be one of the greatest challenges to getting things done. I don't know about you, but I often remember things I need to do in places or times that are not exactly opportune for getting that thing done. So having easy & quick ways for capturing those thoughts with minimal resistance is pretty crucial. Here are a few tools that I use:\r\n\r\n### Widgets\r\n\r\nIf I have a quick thought while I'm on the go, I actually have a widget on my phone (thank you, Android) that lets me tap once, type in the task and it is added directly to my `Triage` list. I have another widget that displays the contents of my `Today` list, as well as link widgets for OneNote pages that I refer to often.\r\n\r\n### Google Assistant & IFTTT (If This Then That)\r\n\r\nFor some reason, I seem to have a lot of my ideas while I'm commuting. I want to be able to capture the thought, but I'm not going to look for my widget when I'm going 80 mph (I mean 65) on the freeway. Luckily, there was already an [IFTTT hook](https://ifttt.com/applets/L3Whbwie-tell-google-assistant-to-create-new-task-card-on-trello) that integrates Trello and my Google Assistant, enabling me to just say, \"Hey Google, Add a task to finish my productivity blog post,\" and voila - the task \"Finish my productivity blog post\" is added to my `Triage` list.\r\n\r\nSome of the things that I record are not necessarily \"tasks.\" They might just be ideas. But by including it on my board, I know I'll need to act on it somehow - and that could mean really fleshing out the idea or just setting aside time to ponder about it and store it in OneNote 👇\r\n\r\n### OneNote\r\n\r\nOneNote does three things for me: keeps my \"big 3\" top of mind during the day, is my daily code journal/digital scratch pad throughout the day, and it acts as my long-term storage for thoughts and ideas.\r\n\r\n#### OneNote Job 1: Big 3\r\n\r\nIn my daily planning, I try to envision my \"Big 3\" that I want to accomplish by then end of the day. These often end up being closer to \"themes\" of tasks than actual broken-down tasks that I can accomplish in a Pomello (more on this later) or two. So I keep a OneNote page open, specific to each day, where I've defined my Big 3 right at the top. This helps me keep them top of mind throughout the day.\r\n\r\n#### OneNote Job 2: Code Journal/Scratch Pad\r\n\r\nIn that same \"Daily Notes\" page, I keep all of my notes for the day. This can be notes from meetings, but more importantly, it's my **code journal**. In my job as a software engineer, I'm constantly trying to solve problems with the constraints that I'm given. There are times when I try _a lot_ of different approaches because I run into road blocks along the way. Sometimes the most obvious approach has a constraint that makes it impossible (or at least more difficult than it's worth), but that usually isn't clear from the start. When I take things back to my team, if someone asks, _\"Why didn't you just do {insert failed approach here}?\"_ I want to be able to give them a clear answer for why I made the decisions that I did.\r\n\r\nIf a decision I make or a constraint that I discover seems like something that would be useful to future developers, I try to leave a quick comment in the code and/or add details somewhere in a documentation file. If it's something I know will be confusing to reviewers without any context, I may also add a comment on my own pull request after I open it. But having one place where I can capture all the thoughts while I'm \"in the zone,\" I don't need to spend precious mental energy thinking about where would be the best place for this information.\r\n\r\n#### OneNote Job 3: Long-Term Storage\r\n\r\nI love the ability OneNote gives me to compartmentalize things into notebooks, sections, pages, and even sub-pages. Everything is searchable (even the handwriting pages from notes I've taken on my Surface), which makes it great if I can remember just a word or two from the note I'm looking for. I don't use it as my \"bucket\" for new thoughts/ideas, mostly because I don't want to have to think about which \"bucket\" to use when a thought pops up. OneNote is more of a final resting ground for the ideas once I've been able to find them a home that makes sense.\r\n\r\n## Automation Tools\r\n\r\nI. love. automation. That's actually one of the main reasons I got into computer science. I'm not like some developers, who remember programming on the Altair 8800 their dad brought home from work. No, my first \"programming experience\" came out of a more practical necessity. As a 10-year old with an extensive basketball, baseball and football card collection, I wanted a quick and easy way to manage and track my precious assets, which would make me more effective in trading cards with my friends. I built a simple spreadsheet containing all of my cards, with columns for attributes describing the card such as `Player`, `Team`, `Year`, `Is Rookie Card`, etc. From the moment I wrote a simple `=SUM(` formula that counted the number of Rookie Cards I owned without having to count them myself, I was forever changed. I discovered that I could have a computer do something menial _for me_, and that it would free me up to focus on higher level thinking or tasks, such as being the GM of my own cardboard multi-sport franchise.\r\n\r\nI try to automate as many simple tasks as I can so that I don't have to think about them, freeing me up to focus on the bigger picture or my current task at hand.\r\n\r\n### Butler\r\n\r\nAt last, you've made it to the section you've been waiting for. It's been a long, rough journey through these last few paragraphs... but we made it.\r\n\r\n![alt text](https://media1.giphy.com/media/fdyZ3qI0GVZC0/giphy.gif?cid=790b7611707d466850a101fdfb23e9064c7f757ed770c1c3&rid=giphy.gif)\r\n\r\n[Butler](https://help.trello.com/article/1198-an-intro-to-butler) was originally developed as a 3rd party Trello add-in, but was recently acquired by Trello to be a native part of the platform. It's a tool for automating tasks in Trello. Users can set up actions that are triggered by certain rules, due dates of cards, specific times in a day, week or month, etc.\r\n\r\nHere are some example Butler actions that I have run on my board:\r\n\r\n- When a card is added to list \"Done\", mark the due date as complete, and check all the items in all the checklists on the card\r\n- When a card is added to the board by me, add an empty checklist named \"Acceptance Criteria\" to the card\r\n- Every Friday at 6:00 pm, copy each card in list \"Templates\" with a name starting with \"Maintenance Tasks\" to list \"Today\"\r\n- Every Friday at 6:00 pm, move 1 randomly-selected cards from list \"Things I'd like to do\" to list \"This Week\"\r\n- On the Saturday before a card is due at 5:00 pm, move the card to the top of list \"This Week\"\r\n- When a card with a name starting with \"Pack for\" is added to the board, add the \"Packing List\" checklist from card \"Packing List\" to the card\r\n- 2 days before a card is due, move the card to the top of list \"Today\"\r\n- When a card is added to list \"Work\", add the blue \"Work\" label to the card\r\n- Every day at 3:00 am, move all the cards in list \"Today\" to list \"This Week\", sort the cards in list \"This Week\" by due date ascending, and copy each card in list \"Templates\" with a name starting with \"Prepare Mind, Body and Spirit for Today\" to the top of list \"Today\"\r\n\r\nNot all of these actions are currently running on my board. I've played around with lots of different actions to see what works best, but I wanted to provide you with some concrete examples of things that I've used so that you can experiment for yourself.\r\n\r\n#### Side Note - My Own Version of Butler\r\n\r\nNot to be salty, but I actually built a less extensible, harder-to-use and less popular version of Butler a little while ago without even knowing that Butler existed... so we'll just say they stole my idea.\r\n\r\n![alt text](https://media.giphy.com/media/SAOfJWFSQU91vBlYWJ/giphy.gif)\r\n\r\nMine was called [TaskBoardAssistant](https://github.com/tbarlow12/task-board-assistant) (catchy name, right?). Basically it was a concise way to define policies that would ideally be run on a timer trigger, usually from a serverless environment (Azure Functions in my case). Users would create a `.yml` file that contained the filters and actions for different Trello entities. I built a NuGet package that was able to read the `.yml` file and use the [Manatee.Trello SDK](https://github.com/gregsdennis/Manatee.Trello) to perform basic actions like moving, creating, archiving and copying cards, sorting lists, generating reports, etc.\r\n\r\nOriginally, [TaskBoardAssistant](https://github.com/tbarlow12/task-board-assistant) was meant to be bigger than just Trello. In my work at Microsoft, we use a lot of different incarnations of \"task boards\" such as GitHub projects and Azure DevOps (the artist formerly known as Visual Studio Online). I wanted one policy to rule them all... Something that would copy stories/tasks/issues assigned to me in either GitHub or AzDO and then bring them to my Trello board where I was most comfortable interacting with them. The project is still there, and maybe someday I'll contribute more to it. But since I discovered Butler and IFTTT, it seems like those are the most likely path of adoption is within the ecosystem, and I'll probably refocus my efforts there.\r\n\r\n## Focus Tools\r\n\r\n### Pomello\r\n\r\n[Pomello](https://pomelloapp.com/) is my \"runtime\" task management tool. My trusted companion on the battlefield of daily productivity. She keeps me accountable, focused and in the zone.\r\n\r\nYou may be familiar with the [Pomodoro](https://en.wikipedia.org/wiki/Pomodoro_Technique) system. If not, it's basically 25 minutes of focused work, 5 minute break. Do four of those cycles, and take a longer break. I think 25 minutes works great, and obviously a lot of people have had success with it (myself included). But after a [study done by Dr. Travis Bradberry](https://qz.com/work/1561830/why-the-eight-hour-workday-doesnt-work/), I adjusted to doing hour-long intervals with 15 minute breaks. I could go more into detail on that, but I'll save that for another time.\r\n\r\nPomello is a simple app that takes the Pomodoro system and applies it to my Trello tasks. When you start it up for the first time, you log into your Trello account. Then, you pick a list to work off of. Mine is the `Today` list if you didn't guess that already. Pomello then asks you to pick a task.\r\n\r\n![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/productivity/pomello-1.png?raw=true)\r\n\r\nOnce you pick a task, the app has an extremely satisfying \"clock winding up\" sound that plays when you start a new task.\r\n\r\n![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/productivity/pomello-2.png?raw=true)\r\n\r\nThe timer runs for `x` minutes (25 by default, but you can adjust that), and Pomello will actually log on your Trello card how many (even fractional) Pomodoros you've spent working on that task.\r\n\r\n![alt text](https://github.com/tbarlow12/tbarlow12.github.io/blob/dev/resources/images/productivity/pomello-3.png?raw=true)\r\n\r\nI love it because it keeps me focused on what I'm working on and forces me to time-box the work that I do. If a task requires more than 3 or 4 Pomodoros, I probably should've broken it down a little bit more. It also gives me the opportunity to reflect on how long a task actually took, and how good my estimate 👇 actually was.\r\n\r\n### Agile Tools\r\n\r\nAnother 3rd-party \"Power Up\" that I use on my Trello board is [Agile Tools](https://getcorrello.com/AgileTools). This allows me a quick way to add an estimate for each of the cards. The estimate is in \"story points,\" which can mean different things to different people. To make it simple for all my tasks, I equate 1 story point with 1 Pomodoro. And since Pomello logs how many Pomodoros I spend on each task, it gives me a good way to evaluate my estimates for each task. As part of my weekly planning, I give an estimate for each task. Also, in my daily planning, if any tasks from my `Triage` list land in my `This Week` or `Today` lists, I add estimates for those too.\r\n\r\nAnother nice feature added by Agile Tools is WIP Limits. I can set the maximum number of cards that should exist in a list. If I go over that number, there is a red badge on each of the cards that tells me how many cards are in that list, and how many cards there *should* be. I set my WIP Limit for `This Week` to 20, and my limit for `Today` is 5 (4 cards per weekday, counting on leaving one spot for tasks that come up during the week).\r\n\r\n### WasteNoTime\r\n\r\n[WasteNoTime](https://chrome.google.com/webstore/detail/wastenotime/enebomhlllfaccbelnjhfgblnalofhch?hl=en) is a Chrome extension that keeps me accountable for the websites I visit. I can set schedules for when I can/can't visit a certain URL, and if I try to violate the rules, it pops up with a quote about productivity/time management and asks \"Shouldn't you be working?\" This makes it much easier to avoid wasting time on sites that don't add any real value to my day.\r\n\r\n### AppBlock\r\n\r\n[AppBlock](https://play.google.com/store/apps/details?id=cz.mobilesoft.appblock) does the same job for me as WasteNoTime, but on my phone. I can set time limits and schedules for when applications or websites can or can't be accessed. That way, I have more than just my willpower to stop me from using my phone as an escape hatch when I'm tired or bored.\r\n\r\n## Habits\r\n\r\n### Daily Preparation\r\n\r\nI try to start every day of my life by doing things to prepare my mind, body and spirit for a new day. Those things are:\r\n\r\n- Personal prayer on my knees\r\n- 30 minutes studying scriptures\r\n- Recite my personal creed\r\n- 10 minutes drawing a mind map\r\n- ~40 minutes working out (except on Sunday)\r\n- 10 minutes meditating\r\n- Create a meaningful plan for the day (see Daily Planning below)\r\n\r\nI've found that if I skip even one of these daily rituals, I can feel a difference during the day. On days that I get all 7, I feel pretty unstoppable.\r\n\r\n![alt text](https://media.giphy.com/media/LSX5dYGZJ2Z7fy5rA4/giphy.gif)\r\n\r\nThere are times when I can spend more time on some of these tasks, other times I spend less. I've learned from being a dad of two little boys that I need to just take whatever time they'll give me. Usually, this just means getting up early to finish most of these tasks before they get up.\r\n\r\n### Daily Planning\r\n\r\nMy Daily Planning follows these exact steps:\r\n\r\n- Begin your planning with a prayer for help and guidance as you decide what you will do today\r\n- Check your work sprint board at work to make sure you've captured all tasks assigned to you as cards and add them to your Triage list\r\n- Triage all items in your triage list by categorizing them, estimating them, adding a due date if necessary and placing them in the correct place by priority\r\n- Move the tasks from your 'This Week' list that you commit to finishing today to your 'Today' list. If there is a task that you cannot finish in a day, break it down into smaller tasks. If you are blocked by something, move that task to your 'Waiting For' list and write down what you are waiting for\r\n- Scan your 'Waiting For' list to see if any conditions have changed that will allow you to move forward\r\n- Visualize the end of your day. What are the most important three things that you could accomplish today? Write them down in your \"Daily Notes Page\r\n- Conclude your planning with a prayer for help to finish the tasks you have committed to doing today\r\n\r\nBy having a deliberate plan for what I will do that day, I don't waste any time deciding what to do next. I can just focus on annihilating any task that is foolish enough to face me.\r\n\r\n### Weekly Planning\r\n\r\nThe main purpose of my weekly planning is to keep the big picture in focus while enabling quick and easy daily planning sessions. Here are the main steps to my weekly planning session:\r\n\r\n- Begin your planning with a prayer for help and guidance as you decide what you will do this week\r\n- Spend 5:00 writing down everything that went well this last week\r\n- Spend 5:00 writing down things you could have done better this week\r\n- Plan any action items based on this week's retrospective\r\n- Go through each categorical list and determine if any of the tasks on that list **need** to be done this week\r\n- Filter, remove or combine cards if necessary to make sure you have no more than 20 cards for the week\r\n- Add estimates for each item on the list\r\n- Add due dates for each item on the list, making sure each day has a balanced number of tasks\r\n- (...run through my [hotspots](https://alifeofproductivity.com/your-life-at-10000-feet-hotspots-time-energy/) and the predefined tasks I've associated with each of them. Examples: Plan date night for the week, Plan for upcoming traditions, Plan to reach out to an old friend, Plan your workouts for the week, Label expenses in money tracking tool, etc.)\r\n- Conclude your planning with a prayer for help to finish the tasks you have committed to doing this week\r\n\r\nI try to hold my planning session on Saturday morning, but it is often fragmented into any time I can find (could be Saturday morning, nap time, night, Sunday morning, nap time, etc.). It's an investment of my time, but one that pays dividends upon dividends throughout the week.\r\n\r\n## Resources\r\n\r\nHere are some of my absolute favorite books that have shaped how I see things like habits, productivity, goals, accountability and fulfillment:\r\n\r\n- How Will You Measure Your Life - Clayton M. Christensen\r\n- Atomic Habits - James Clear\r\n- The Productivity Project - Chris Bailey\r\n- Grit: The Power of Passion and Perseverance - Angela Duckworth\r\n- Algorithms to Live By - Tom Griffiths\r\n- Essentialism - Greg McKeown\r\n- Hyperfocus - Chris Bailey\r\n- The 5 AM Club - Robin Sharma\r\n- Designing Your Life - Dave Evans\r\n- Getting Things Done - David Allen\r\n- The Power to Get Things Done (Whether You Like It or Not) - Chris Cooper\r\n\r\n## Conclusion\r\n\r\nWell, you made it. Certainly farther than I would have made it reading some rando's blog about how he does stuff... I hope that at least *something* in this was useful to you. If this just got you thinking about how you want to get stuff done, even if it's exactly opposite of everything that I'm doing, I'll feel like I've done my job here. If there's something that has worked for you, I'd love to hear about it. Thanks for sticking with me to the end. Until next time 👍\r\n","data":{"title":"Somehow I Manage... My Tasks","date":"2020-5-4","path":"tasks"},"isEmpty":false,"excerpt":""}}